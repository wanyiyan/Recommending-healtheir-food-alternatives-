{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align:center\"><span style=\"color:blue; font-family:Times New Roman; font-size:3em;\"> Data modeling  </span></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import DataFrame, Series\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "#from sklearn.externals import joblib\n",
    "import joblib\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras import backend as K\n",
    "#K.set_image_dim_ordering('th')\n",
    "import h5py\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tqdm import tqdm\n",
    "import copy\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, Reshape,Lambda, Input, RepeatVector\n",
    "from keras.utils import plot_model\n",
    "from keras import initializers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align:justify\"><span style=\"color:black; font-family:Times New Roman; font-size:1.5em;line-height:1.4em;\">I load the train data (X) and the test data (X_test) which are already preprocessed in the previous stage. \n",
    " </span></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction process logic: \n",
    "\n",
    "# X: state of all the items user seen upto order 20th for user 15\n",
    "# Y: whether reordered or no in order 21st for user 15 (one column from X)\n",
    "\n",
    "# X_test: state of all the items seens upto order 21st for user 15\n",
    "# Y_pred: probability for each item have been seen upto 21st for user 15. \n",
    "#         ---> This probability will be the recommendations for order 22nd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X       =pd.read_csv('X_v4.csv')\n",
    "X_test  =pd.read_csv('X_test_v4.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['total_orders_user', 'unique_items_user', 'total_items_user',\n",
       "       'average_items_per_order', 'average_days_per_order', 'appear_rate',\n",
       "       'reorder_num', 'add_to_cart_order', 'total_order_minus_last_order',\n",
       "       'last_order_ratio', 'aisle_id', 'department_id', 'user_num_product',\n",
       "       'product_total_orders', 'product_total_reorders', 'reorder_ratio',\n",
       "       'last_1st_order', 'last_2st_order', 'last_3st_order', 'last_4st_order',\n",
       "       'last_5st_order', 'last_6st_order', 'last_7st_order', 'last_8st_order',\n",
       "       'last_9st_order', 'last_10st_order', 'last_11st_order',\n",
       "       'last_12st_order', 'last_13st_order', 'last_14st_order',\n",
       "       'last_15st_order', 'last_16st_order', 'last_17st_order',\n",
       "       'last_18st_order', 'last_19st_order', 'last_20st_order',\n",
       "       'last_five_orders_sum', 'last_10_orders_sum', 'last_15_orders_sum',\n",
       "       'last_20_orders_sum', 'SAIN_LIM_Point'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X=X.take(np.random.permutation(len(X)))  #shuffle rows in the X. as such no longer on a user level\n",
    "Y=X['reordered']\n",
    "X.drop(['reordered','user_id', 'product_id','Unnamed: 0','Unnamed: 0.1'], axis=1, inplace=True)\n",
    "X_test.drop(['user_id', 'product_id','Unnamed: 0','Unnamed: 0.1'], axis=1, inplace=True)\n",
    "X.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align:justify\"><span style=\"color:black; font-family:Times New Roman; font-size:1.5em;line-height:1.4em;\">The train data is shuffled and divided into the train set (80%) and the validation set (20%) by preserving the same percentage for each target class as in the complete set. In order to train neural network, the data is normalized to be in the range between 0 and 1. \n",
    " </span></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "skf = StratifiedKFold(n_splits=5) # n_split = 5 to have 80% 20% split. now if n_splits = 2, then it is 50% 50% split\n",
    "i=1\n",
    "for train_index, valid_index  in skf.split(X, Y): #X, Y here are train..so for user 15 upto order # 21\n",
    "    joblib.dump(X.values[train_index],'X_train_modify_{}_v4.pkl'.format(i))\n",
    "    joblib.dump(Y.values[train_index],'Y_train_modify_{}_v4.pkl'.format(i))\n",
    "    joblib.dump(X.values[valid_index],'X_valid_modify_{}_v4.pkl'.format(i))\n",
    "    joblib.dump(Y.values[valid_index],'Y_valid_modify_{}_v4.pkl'.format(i))\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align:justify\"><span style=\"color:black; font-family:Times New Roman; font-size:1.5em;line-height:1.4em;\">\n",
    "The neural network structure consists of one input layer, six hidden layers and one output layer. The weights are initialized using small Gaussian random numbers. The Rectifier activation function is used for each hidden layer. Two Dropout layers are applied to prevent overfitting. I also add Batch Normalization to each hidden layer of the network to perform the normalization for each training mini-batch. Batch Normalization allows us to use much higher learning rates and increase model performance. \n",
    "The output layer has a single neuron and a sigmoid activation is used for purposes of probabilistic classification. Finally the logarithmic loss function (binary_crossentropy) during training is used for binary classification. The model uses the efficient Adamax optimization algorithm for gradient descent and accuracy metrics is evaluated when the model is trained. \n",
    "I use the class_weights in the model.fit method to handle the imbalanced train data.\n",
    "The class weights are calculated by inversely proportional to class frequencies in the input data.\n",
    "I train the network for 500 epochs, with 1000 samples per mini-batch. The model weights that give the best result (lowest loss in the validation set) are saved for model evaluation and prediction of the test data. \n",
    "\n",
    " </span></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot_model(NNmodel, to_file='test1.png',show_shapes=True,show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model generated from \n",
    "\n",
    "def NNmodel(X_scaled_train, y_train,X_scaled_valid, y_valid,optimizer,batch_size,nb_epoch, c1, c2, c3, c4,c5,c6,drop1, \\\n",
    "            drop2, init,testnumber):\n",
    "    model=Sequential()\n",
    "    model.add(Dense(c1, input_dim=X_train.shape[1], init = init, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(drop1))\n",
    "    model.add(Dense(c2, init = init, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(drop2))\n",
    "    model.add(Dense(c3, init = init, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(c4, init = init, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(c5, init = init, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(c6, init = init, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(1, init = init, activation='sigmoid'))\n",
    "  \n",
    "    from sklearn.utils import class_weight\n",
    "    class_weight = class_weight.compute_class_weight('balanced', np.unique(y_train), y_train)\n",
    "    model.compile(loss = 'binary_crossentropy', optimizer = optimizer,metrics=['accuracy']) \n",
    "    filepath=\"model_{}.best_v4.hdf5\".format(testnumber)\n",
    "    saveBestModel = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "    model.fit(X_scaled_train, y_train, batch_size=batch_size, nb_epoch=nb_epoch, class_weight=class_weight,\n",
    "              validation_data=(X_scaled_valid, y_valid),callbacks=[saveBestModel],verbose=1) \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NNmodel_prediction(X_scaled_test,optimizer,batch_size,c1, c2, c3, c4,c5,c6,drop1, drop2, init,testnumber):\n",
    "    model=Sequential()\n",
    "    model.add(Dense(c1, input_dim=X_train.shape[1], init = init, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(drop1))\n",
    "    model.add(Dense(c2, init = init, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(drop2))\n",
    "    model.add(Dense(c3, init = init, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(c4, init = init, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(c5, init = init, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(c6, init = init, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(1, init = init, activation='sigmoid'))\n",
    "  \n",
    "    filepath=\"model_{}.best_v4.hdf5\".format(testnumber)\n",
    "    model.load_weights(filepath)\n",
    "    model.compile(loss = 'binary_crossentropy', optimizer = optimizer,metrics=['accuracy']) \n",
    "    y_pred_test = model.predict_proba(X_scaled_test, batch_size=batch_size, verbose=1)\n",
    "    return y_pred_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align:justify\"><span style=\"color:black; font-family:Times New Roman; font-size:1.5em;line-height:1.4em;\">\n",
    "Five-fold train/validation combinations are iterated and trained in the neural network model. The test data is fed into the model which generates 5 predictions via the iterations. The final prediction for the test data is obtained by averaging all 5 predictions in order to reduce overfitting.\n",
    "\n",
    " </span></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                            | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 919289 samples, validate on 229823 samples\n",
      "Epoch 1/100\n",
      "919289/919289 [==============================] - 84s 92us/step - loss: 0.2373 - accuracy: 0.9205 - val_loss: 0.2161 - val_accuracy: 0.9242\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.21610, saving model to model_1.best_v4.hdf5\n",
      "Epoch 2/100\n",
      "919289/919289 [==============================] - 104s 113us/step - loss: 0.2097 - accuracy: 0.9274 - val_loss: 0.2086 - val_accuracy: 0.9276\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.21610 to 0.20863, saving model to model_1.best_v4.hdf5\n",
      "Epoch 3/100\n",
      "919289/919289 [==============================] - 82s 89us/step - loss: 0.2088 - accuracy: 0.9276 - val_loss: 0.2074 - val_accuracy: 0.9279\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.20863 to 0.20742, saving model to model_1.best_v4.hdf5\n",
      "Epoch 4/100\n",
      "919289/919289 [==============================] - 84s 91us/step - loss: 0.2082 - accuracy: 0.9276 - val_loss: 0.2078 - val_accuracy: 0.9276\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.20742\n",
      "Epoch 5/100\n",
      "919289/919289 [==============================] - 81s 89us/step - loss: 0.2077 - accuracy: 0.9276 - val_loss: 0.2078 - val_accuracy: 0.9276\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.20742\n",
      "Epoch 6/100\n",
      "919289/919289 [==============================] - 82s 90us/step - loss: 0.2074 - accuracy: 0.9277 - val_loss: 0.2072 - val_accuracy: 0.9279\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.20742 to 0.20717, saving model to model_1.best_v4.hdf5\n",
      "Epoch 7/100\n",
      "919289/919289 [==============================] - 74s 80us/step - loss: 0.2071 - accuracy: 0.9279 - val_loss: 0.2072 - val_accuracy: 0.9278\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.20717 to 0.20716, saving model to model_1.best_v4.hdf5\n",
      "Epoch 8/100\n",
      "919289/919289 [==============================] - 71s 77us/step - loss: 0.2070 - accuracy: 0.9279 - val_loss: 0.2081 - val_accuracy: 0.9270\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.20716\n",
      "Epoch 9/100\n",
      "919289/919289 [==============================] - 72s 78us/step - loss: 0.2068 - accuracy: 0.9279 - val_loss: 0.2070 - val_accuracy: 0.9281\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.20716 to 0.20699, saving model to model_1.best_v4.hdf5\n",
      "Epoch 10/100\n",
      "919289/919289 [==============================] - 72s 78us/step - loss: 0.2068 - accuracy: 0.9277 - val_loss: 0.2075 - val_accuracy: 0.9276\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.20699\n",
      "Epoch 11/100\n",
      "919289/919289 [==============================] - 73s 79us/step - loss: 0.2066 - accuracy: 0.9280 - val_loss: 0.2066 - val_accuracy: 0.9280\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.20699 to 0.20661, saving model to model_1.best_v4.hdf5\n",
      "Epoch 12/100\n",
      "919289/919289 [==============================] - 76s 82us/step - loss: 0.2066 - accuracy: 0.9279 - val_loss: 0.2066 - val_accuracy: 0.9280\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.20661 to 0.20659, saving model to model_1.best_v4.hdf5\n",
      "Epoch 13/100\n",
      "919289/919289 [==============================] - 72s 78us/step - loss: 0.2065 - accuracy: 0.9280 - val_loss: 0.2067 - val_accuracy: 0.9279\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.20659\n",
      "Epoch 14/100\n",
      "919289/919289 [==============================] - 72s 79us/step - loss: 0.2065 - accuracy: 0.9278 - val_loss: 0.2070 - val_accuracy: 0.9279\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.20659\n",
      "Epoch 15/100\n",
      "919289/919289 [==============================] - 73s 79us/step - loss: 0.2064 - accuracy: 0.9279 - val_loss: 0.2064 - val_accuracy: 0.9282\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.20659 to 0.20638, saving model to model_1.best_v4.hdf5\n",
      "Epoch 16/100\n",
      "919289/919289 [==============================] - 78s 85us/step - loss: 0.2062 - accuracy: 0.9280 - val_loss: 0.2065 - val_accuracy: 0.9282\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.20638\n",
      "Epoch 17/100\n",
      "919289/919289 [==============================] - 72s 78us/step - loss: 0.2061 - accuracy: 0.9280 - val_loss: 0.2065 - val_accuracy: 0.9280\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.20638\n",
      "Epoch 18/100\n",
      "919289/919289 [==============================] - 72s 79us/step - loss: 0.2061 - accuracy: 0.9279 - val_loss: 0.2072 - val_accuracy: 0.9273\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.20638\n",
      "Epoch 19/100\n",
      "919289/919289 [==============================] - 76s 83us/step - loss: 0.2062 - accuracy: 0.9278 - val_loss: 0.2073 - val_accuracy: 0.9278\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.20638\n",
      "Epoch 20/100\n",
      "919289/919289 [==============================] - 72s 79us/step - loss: 0.2060 - accuracy: 0.9280 - val_loss: 0.2069 - val_accuracy: 0.9282\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.20638\n",
      "Epoch 21/100\n",
      "919289/919289 [==============================] - 74s 80us/step - loss: 0.2059 - accuracy: 0.9282 - val_loss: 0.2067 - val_accuracy: 0.9279\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.20638\n",
      "Epoch 22/100\n",
      "919289/919289 [==============================] - 75s 81us/step - loss: 0.2059 - accuracy: 0.9281 - val_loss: 0.2064 - val_accuracy: 0.9281\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.20638 to 0.20636, saving model to model_1.best_v4.hdf5\n",
      "Epoch 23/100\n",
      "919289/919289 [==============================] - 72s 79us/step - loss: 0.2058 - accuracy: 0.9281 - val_loss: 0.2069 - val_accuracy: 0.9275\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.20636\n",
      "Epoch 24/100\n",
      "919289/919289 [==============================] - 77s 83us/step - loss: 0.2057 - accuracy: 0.9281 - val_loss: 0.2064 - val_accuracy: 0.9281\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.20636 to 0.20635, saving model to model_1.best_v4.hdf5\n",
      "Epoch 25/100\n",
      "919289/919289 [==============================] - 73s 80us/step - loss: 0.2058 - accuracy: 0.9281 - val_loss: 0.2064 - val_accuracy: 0.9281\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.20635\n",
      "Epoch 26/100\n",
      "919289/919289 [==============================] - 75s 81us/step - loss: 0.2055 - accuracy: 0.9282 - val_loss: 0.2073 - val_accuracy: 0.9277\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.20635\n",
      "Epoch 27/100\n",
      "919289/919289 [==============================] - 76s 82us/step - loss: 0.2055 - accuracy: 0.9283 - val_loss: 0.2068 - val_accuracy: 0.9277\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.20635\n",
      "Epoch 28/100\n",
      "919289/919289 [==============================] - 72s 79us/step - loss: 0.2055 - accuracy: 0.9283 - val_loss: 0.2064 - val_accuracy: 0.9282\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.20635\n",
      "Epoch 29/100\n",
      "919289/919289 [==============================] - 73s 79us/step - loss: 0.2054 - accuracy: 0.9282 - val_loss: 0.2067 - val_accuracy: 0.9281\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.20635\n",
      "Epoch 30/100\n",
      "919289/919289 [==============================] - 78s 85us/step - loss: 0.2054 - accuracy: 0.9282 - val_loss: 0.2065 - val_accuracy: 0.9282\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.20635\n",
      "Epoch 31/100\n",
      "919289/919289 [==============================] - 72s 78us/step - loss: 0.2052 - accuracy: 0.9283 - val_loss: 0.2068 - val_accuracy: 0.9282\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.20635\n",
      "Epoch 32/100\n",
      "919289/919289 [==============================] - 77s 84us/step - loss: 0.2052 - accuracy: 0.9283 - val_loss: 0.2067 - val_accuracy: 0.9282\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.20635\n",
      "Epoch 33/100\n",
      "919289/919289 [==============================] - 72s 78us/step - loss: 0.2052 - accuracy: 0.9283 - val_loss: 0.2065 - val_accuracy: 0.9281\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.20635\n",
      "Epoch 34/100\n",
      "919289/919289 [==============================] - 76s 83us/step - loss: 0.2052 - accuracy: 0.9283 - val_loss: 0.2071 - val_accuracy: 0.9281\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.20635\n",
      "Epoch 35/100\n",
      "919289/919289 [==============================] - 73s 79us/step - loss: 0.2050 - accuracy: 0.9283 - val_loss: 0.2067 - val_accuracy: 0.9281\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.20635\n",
      "Epoch 36/100\n",
      "919289/919289 [==============================] - 77s 84us/step - loss: 0.2049 - accuracy: 0.9283 - val_loss: 0.2064 - val_accuracy: 0.9283\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.20635\n",
      "Epoch 37/100\n",
      "919289/919289 [==============================] - 74s 80us/step - loss: 0.2049 - accuracy: 0.9283 - val_loss: 0.2081 - val_accuracy: 0.9279\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.20635\n",
      "Epoch 38/100\n",
      "919289/919289 [==============================] - 73s 80us/step - loss: 0.2049 - accuracy: 0.9284 - val_loss: 0.2065 - val_accuracy: 0.9283\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00038: val_loss did not improve from 0.20635\n",
      "Epoch 39/100\n",
      "919289/919289 [==============================] - 73s 80us/step - loss: 0.2049 - accuracy: 0.9283 - val_loss: 0.2073 - val_accuracy: 0.9281\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.20635\n",
      "Epoch 40/100\n",
      "919289/919289 [==============================] - 72s 78us/step - loss: 0.2047 - accuracy: 0.9284 - val_loss: 0.2075 - val_accuracy: 0.9282\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.20635\n",
      "Epoch 41/100\n",
      "919289/919289 [==============================] - 76s 82us/step - loss: 0.2048 - accuracy: 0.9283 - val_loss: 0.2069 - val_accuracy: 0.9281\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.20635\n",
      "Epoch 42/100\n",
      "919289/919289 [==============================] - 72s 78us/step - loss: 0.2046 - accuracy: 0.9284 - val_loss: 0.2067 - val_accuracy: 0.9282\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.20635\n",
      "Epoch 43/100\n",
      "919289/919289 [==============================] - 74s 81us/step - loss: 0.2048 - accuracy: 0.9284 - val_loss: 0.2067 - val_accuracy: 0.9282\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.20635\n",
      "Epoch 44/100\n",
      "919289/919289 [==============================] - 72s 78us/step - loss: 0.2045 - accuracy: 0.9285 - val_loss: 0.2066 - val_accuracy: 0.9281\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.20635\n",
      "Epoch 45/100\n",
      "919289/919289 [==============================] - 71s 78us/step - loss: 0.2044 - accuracy: 0.9286 - val_loss: 0.2067 - val_accuracy: 0.9280\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.20635\n",
      "Epoch 46/100\n",
      "919289/919289 [==============================] - 75s 81us/step - loss: 0.2045 - accuracy: 0.9285 - val_loss: 0.2067 - val_accuracy: 0.9282\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.20635\n",
      "Epoch 47/100\n",
      "919289/919289 [==============================] - 74s 81us/step - loss: 0.2042 - accuracy: 0.9286 - val_loss: 0.2070 - val_accuracy: 0.9282\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.20635\n",
      "Epoch 48/100\n",
      "919289/919289 [==============================] - 72s 78us/step - loss: 0.2043 - accuracy: 0.9286 - val_loss: 0.2069 - val_accuracy: 0.9282\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.20635\n",
      "Epoch 49/100\n",
      "919289/919289 [==============================] - 71s 78us/step - loss: 0.2042 - accuracy: 0.9286 - val_loss: 0.2070 - val_accuracy: 0.9282\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.20635\n",
      "Epoch 50/100\n",
      "919289/919289 [==============================] - 75s 82us/step - loss: 0.2042 - accuracy: 0.9286 - val_loss: 0.2066 - val_accuracy: 0.9283\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.20635\n",
      "Epoch 51/100\n",
      "919289/919289 [==============================] - 74s 81us/step - loss: 0.2041 - accuracy: 0.9286 - val_loss: 0.2069 - val_accuracy: 0.9282\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.20635\n",
      "Epoch 52/100\n",
      "919289/919289 [==============================] - 71s 78us/step - loss: 0.2041 - accuracy: 0.9286 - val_loss: 0.2068 - val_accuracy: 0.9280\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.20635\n",
      "Epoch 53/100\n",
      "919289/919289 [==============================] - 73s 79us/step - loss: 0.2040 - accuracy: 0.9286 - val_loss: 0.2066 - val_accuracy: 0.9282\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.20635\n",
      "Epoch 54/100\n",
      "919289/919289 [==============================] - 73s 79us/step - loss: 0.2040 - accuracy: 0.9286 - val_loss: 0.2067 - val_accuracy: 0.9281\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.20635\n",
      "Epoch 55/100\n",
      "919289/919289 [==============================] - 72s 79us/step - loss: 0.2039 - accuracy: 0.9286 - val_loss: 0.2067 - val_accuracy: 0.9282\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.20635\n",
      "Epoch 56/100\n",
      "919289/919289 [==============================] - 76s 83us/step - loss: 0.2037 - accuracy: 0.9288 - val_loss: 0.2068 - val_accuracy: 0.9283\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.20635\n",
      "Epoch 57/100\n",
      "919289/919289 [==============================] - 72s 79us/step - loss: 0.2039 - accuracy: 0.9287 - val_loss: 0.2066 - val_accuracy: 0.9283\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.20635\n",
      "Epoch 58/100\n",
      "919289/919289 [==============================] - 72s 78us/step - loss: 0.2039 - accuracy: 0.9287 - val_loss: 0.2073 - val_accuracy: 0.9281\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.20635\n",
      "Epoch 59/100\n",
      "919289/919289 [==============================] - 74s 80us/step - loss: 0.2037 - accuracy: 0.9287 - val_loss: 0.2071 - val_accuracy: 0.9282\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.20635\n",
      "Epoch 60/100\n",
      "919289/919289 [==============================] - 74s 80us/step - loss: 0.2036 - accuracy: 0.9286 - val_loss: 0.2072 - val_accuracy: 0.9279\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.20635\n",
      "Epoch 61/100\n",
      "919289/919289 [==============================] - 74s 81us/step - loss: 0.2037 - accuracy: 0.9286 - val_loss: 0.2069 - val_accuracy: 0.9283\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.20635\n",
      "Epoch 62/100\n",
      "919289/919289 [==============================] - 74s 80us/step - loss: 0.2036 - accuracy: 0.9288 - val_loss: 0.2072 - val_accuracy: 0.9282\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.20635\n",
      "Epoch 63/100\n",
      "919289/919289 [==============================] - 73s 79us/step - loss: 0.2035 - accuracy: 0.9287 - val_loss: 0.2069 - val_accuracy: 0.9281\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.20635\n",
      "Epoch 64/100\n",
      "919289/919289 [==============================] - 72s 79us/step - loss: 0.2035 - accuracy: 0.9287 - val_loss: 0.2070 - val_accuracy: 0.9282\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.20635\n",
      "Epoch 65/100\n",
      "919289/919289 [==============================] - 77s 84us/step - loss: 0.2033 - accuracy: 0.9288 - val_loss: 0.2069 - val_accuracy: 0.9280\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.20635\n",
      "Epoch 66/100\n",
      "919289/919289 [==============================] - 72s 78us/step - loss: 0.2033 - accuracy: 0.9287 - val_loss: 0.2070 - val_accuracy: 0.9282\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.20635\n",
      "Epoch 67/100\n",
      "919289/919289 [==============================] - 74s 80us/step - loss: 0.2033 - accuracy: 0.9287 - val_loss: 0.2069 - val_accuracy: 0.9283\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.20635\n",
      "Epoch 68/100\n",
      "919289/919289 [==============================] - 75s 82us/step - loss: 0.2034 - accuracy: 0.9288 - val_loss: 0.2072 - val_accuracy: 0.9284\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.20635\n",
      "Epoch 69/100\n",
      "919289/919289 [==============================] - 72s 78us/step - loss: 0.2033 - accuracy: 0.9288 - val_loss: 0.2075 - val_accuracy: 0.9281\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.20635\n",
      "Epoch 70/100\n",
      "919289/919289 [==============================] - 75s 82us/step - loss: 0.2032 - accuracy: 0.9288 - val_loss: 0.2070 - val_accuracy: 0.9283\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.20635\n",
      "Epoch 71/100\n",
      "919289/919289 [==============================] - 73s 80us/step - loss: 0.2032 - accuracy: 0.9288 - val_loss: 0.2071 - val_accuracy: 0.9283\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.20635\n",
      "Epoch 72/100\n",
      "919289/919289 [==============================] - 72s 78us/step - loss: 0.2030 - accuracy: 0.9288 - val_loss: 0.2069 - val_accuracy: 0.9283\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.20635\n",
      "Epoch 73/100\n",
      "919289/919289 [==============================] - 76s 83us/step - loss: 0.2030 - accuracy: 0.9287 - val_loss: 0.2071 - val_accuracy: 0.9282\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.20635\n",
      "Epoch 74/100\n",
      "919289/919289 [==============================] - 73s 79us/step - loss: 0.2030 - accuracy: 0.9288 - val_loss: 0.2070 - val_accuracy: 0.9282\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.20635\n",
      "Epoch 75/100\n",
      "919289/919289 [==============================] - 74s 80us/step - loss: 0.2030 - accuracy: 0.9288 - val_loss: 0.2070 - val_accuracy: 0.9283\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.20635\n",
      "Epoch 76/100\n",
      "919289/919289 [==============================] - 73s 79us/step - loss: 0.2029 - accuracy: 0.9288 - val_loss: 0.2073 - val_accuracy: 0.9282\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.20635\n",
      "Epoch 77/100\n",
      "919289/919289 [==============================] - 73s 79us/step - loss: 0.2029 - accuracy: 0.9288 - val_loss: 0.2070 - val_accuracy: 0.9283\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.20635\n",
      "Epoch 78/100\n",
      "919289/919289 [==============================] - 75s 81us/step - loss: 0.2028 - accuracy: 0.9289 - val_loss: 0.2077 - val_accuracy: 0.9282\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.20635\n",
      "Epoch 79/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "919289/919289 [==============================] - 74s 81us/step - loss: 0.2028 - accuracy: 0.9289 - val_loss: 0.2073 - val_accuracy: 0.9281\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.20635\n",
      "Epoch 80/100\n",
      "919289/919289 [==============================] - 69s 75us/step - loss: 0.2029 - accuracy: 0.9289 - val_loss: 0.2072 - val_accuracy: 0.9284\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.20635\n",
      "Epoch 81/100\n",
      "919289/919289 [==============================] - 74s 80us/step - loss: 0.2027 - accuracy: 0.9290 - val_loss: 0.2071 - val_accuracy: 0.9283\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.20635\n",
      "Epoch 82/100\n",
      "919289/919289 [==============================] - 74s 80us/step - loss: 0.2026 - accuracy: 0.9288 - val_loss: 0.2076 - val_accuracy: 0.9282\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 0.20635\n",
      "Epoch 83/100\n",
      "919289/919289 [==============================] - 71s 78us/step - loss: 0.2025 - accuracy: 0.9288 - val_loss: 0.2072 - val_accuracy: 0.9285\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 0.20635\n",
      "Epoch 84/100\n",
      "919289/919289 [==============================] - 73s 80us/step - loss: 0.2025 - accuracy: 0.9290 - val_loss: 0.2073 - val_accuracy: 0.9283\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.20635\n",
      "Epoch 85/100\n",
      "919289/919289 [==============================] - 69s 75us/step - loss: 0.2025 - accuracy: 0.9288 - val_loss: 0.2073 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.20635\n",
      "Epoch 86/100\n",
      "919289/919289 [==============================] - 73s 80us/step - loss: 0.2026 - accuracy: 0.9288 - val_loss: 0.2073 - val_accuracy: 0.9283\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.20635\n",
      "Epoch 87/100\n",
      "919289/919289 [==============================] - 71s 77us/step - loss: 0.2025 - accuracy: 0.9289 - val_loss: 0.2081 - val_accuracy: 0.9283\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.20635\n",
      "Epoch 88/100\n",
      "919289/919289 [==============================] - 73s 79us/step - loss: 0.2024 - accuracy: 0.9291 - val_loss: 0.2075 - val_accuracy: 0.9285\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 0.20635\n",
      "Epoch 89/100\n",
      "919289/919289 [==============================] - 69s 75us/step - loss: 0.2024 - accuracy: 0.9290 - val_loss: 0.2073 - val_accuracy: 0.9282\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 0.20635\n",
      "Epoch 90/100\n",
      "919289/919289 [==============================] - 74s 81us/step - loss: 0.2022 - accuracy: 0.9289 - val_loss: 0.2078 - val_accuracy: 0.9285\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.20635\n",
      "Epoch 91/100\n",
      "919289/919289 [==============================] - 70s 76us/step - loss: 0.2024 - accuracy: 0.9290 - val_loss: 0.2075 - val_accuracy: 0.9282\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.20635\n",
      "Epoch 92/100\n",
      "919289/919289 [==============================] - 74s 81us/step - loss: 0.2022 - accuracy: 0.9290 - val_loss: 0.2073 - val_accuracy: 0.9281\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.20635\n",
      "Epoch 93/100\n",
      "919289/919289 [==============================] - 71s 77us/step - loss: 0.2021 - accuracy: 0.9290 - val_loss: 0.2069 - val_accuracy: 0.9285\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.20635\n",
      "Epoch 94/100\n",
      "919289/919289 [==============================] - 73s 80us/step - loss: 0.2022 - accuracy: 0.9289 - val_loss: 0.2078 - val_accuracy: 0.9283\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 0.20635\n",
      "Epoch 95/100\n",
      "919289/919289 [==============================] - 70s 76us/step - loss: 0.2022 - accuracy: 0.9290 - val_loss: 0.2075 - val_accuracy: 0.9282\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.20635\n",
      "Epoch 96/100\n",
      "919289/919289 [==============================] - 72s 79us/step - loss: 0.2021 - accuracy: 0.9290 - val_loss: 0.2076 - val_accuracy: 0.9285\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 0.20635\n",
      "Epoch 97/100\n",
      "919289/919289 [==============================] - 75s 82us/step - loss: 0.2020 - accuracy: 0.9289 - val_loss: 0.2076 - val_accuracy: 0.9284\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 0.20635\n",
      "Epoch 98/100\n",
      "919289/919289 [==============================] - 68s 74us/step - loss: 0.2020 - accuracy: 0.9290 - val_loss: 0.2076 - val_accuracy: 0.9281\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.20635\n",
      "Epoch 99/100\n",
      "919289/919289 [==============================] - 73s 79us/step - loss: 0.2020 - accuracy: 0.9290 - val_loss: 0.2075 - val_accuracy: 0.9284\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 0.20635\n",
      "Epoch 100/100\n",
      "919289/919289 [==============================] - 70s 76us/step - loss: 0.2020 - accuracy: 0.9290 - val_loss: 0.2084 - val_accuracy: 0.9283\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 0.20635\n",
      "1178576/1178576 [==============================] - 33s 28us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|███████████████▌                                                              | 1/5 [2:03:56<8:15:45, 7436.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 919289 samples, validate on 229823 samples\n",
      "Epoch 1/100\n",
      "919289/919289 [==============================] - 72s 78us/step - loss: 0.2376 - accuracy: 0.9200 - val_loss: 0.2111 - val_accuracy: 0.9271\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.21107, saving model to model_2.best_v4.hdf5\n",
      "Epoch 2/100\n",
      "919289/919289 [==============================] - 70s 76us/step - loss: 0.2100 - accuracy: 0.9274 - val_loss: 0.2089 - val_accuracy: 0.9273\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.21107 to 0.20886, saving model to model_2.best_v4.hdf5\n",
      "Epoch 3/100\n",
      "919289/919289 [==============================] - 75s 82us/step - loss: 0.2088 - accuracy: 0.9276 - val_loss: 0.2071 - val_accuracy: 0.9280\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.20886 to 0.20710, saving model to model_2.best_v4.hdf5\n",
      "Epoch 4/100\n",
      "919289/919289 [==============================] - 70s 76us/step - loss: 0.2081 - accuracy: 0.9277 - val_loss: 0.2095 - val_accuracy: 0.9268\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.20710\n",
      "Epoch 5/100\n",
      "919289/919289 [==============================] - 74s 81us/step - loss: 0.2078 - accuracy: 0.9277 - val_loss: 0.2070 - val_accuracy: 0.9279\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.20710 to 0.20696, saving model to model_2.best_v4.hdf5\n",
      "Epoch 6/100\n",
      "919289/919289 [==============================] - 69s 75us/step - loss: 0.2074 - accuracy: 0.9278 - val_loss: 0.2114 - val_accuracy: 0.9245\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.20696\n",
      "Epoch 7/100\n",
      "919289/919289 [==============================] - 75s 81us/step - loss: 0.2073 - accuracy: 0.9277 - val_loss: 0.2065 - val_accuracy: 0.9280\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.20696 to 0.20651, saving model to model_2.best_v4.hdf5\n",
      "Epoch 8/100\n",
      "919289/919289 [==============================] - 72s 78us/step - loss: 0.2072 - accuracy: 0.9278 - val_loss: 0.2066 - val_accuracy: 0.9280\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.20651\n",
      "Epoch 9/100\n",
      "919289/919289 [==============================] - 71s 77us/step - loss: 0.2070 - accuracy: 0.9279 - val_loss: 0.2067 - val_accuracy: 0.9276\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.20651\n",
      "Epoch 10/100\n",
      "919289/919289 [==============================] - 73s 79us/step - loss: 0.2068 - accuracy: 0.9279 - val_loss: 0.2060 - val_accuracy: 0.9280\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.20651 to 0.20595, saving model to model_2.best_v4.hdf5\n",
      "Epoch 11/100\n",
      "919289/919289 [==============================] - 71s 78us/step - loss: 0.2068 - accuracy: 0.9279 - val_loss: 0.2060 - val_accuracy: 0.9281\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.20595\n",
      "Epoch 12/100\n",
      "919289/919289 [==============================] - 76s 83us/step - loss: 0.2067 - accuracy: 0.9279 - val_loss: 0.2061 - val_accuracy: 0.9280\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.20595\n",
      "Epoch 13/100\n",
      "919289/919289 [==============================] - 69s 75us/step - loss: 0.2067 - accuracy: 0.9278 - val_loss: 0.2062 - val_accuracy: 0.9278\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.20595\n",
      "Epoch 14/100\n",
      "919289/919289 [==============================] - 76s 83us/step - loss: 0.2065 - accuracy: 0.9280 - val_loss: 0.2060 - val_accuracy: 0.9279\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.20595 to 0.20595, saving model to model_2.best_v4.hdf5\n",
      "Epoch 15/100\n",
      "919289/919289 [==============================] - 69s 75us/step - loss: 0.2064 - accuracy: 0.9280 - val_loss: 0.2062 - val_accuracy: 0.9281\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.20595\n",
      "Epoch 16/100\n",
      "919289/919289 [==============================] - 73s 80us/step - loss: 0.2064 - accuracy: 0.9279 - val_loss: 0.2061 - val_accuracy: 0.9279\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.20595\n",
      "Epoch 17/100\n",
      "919289/919289 [==============================] - 74s 80us/step - loss: 0.2063 - accuracy: 0.9280 - val_loss: 0.2062 - val_accuracy: 0.9281\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.20595\n",
      "Epoch 18/100\n",
      "919289/919289 [==============================] - 69s 75us/step - loss: 0.2063 - accuracy: 0.9281 - val_loss: 0.2062 - val_accuracy: 0.9276\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.20595\n",
      "Epoch 19/100\n",
      "919289/919289 [==============================] - 74s 81us/step - loss: 0.2062 - accuracy: 0.9280 - val_loss: 0.2059 - val_accuracy: 0.9279\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.20595 to 0.20595, saving model to model_2.best_v4.hdf5\n",
      "Epoch 20/100\n",
      "919289/919289 [==============================] - 70s 76us/step - loss: 0.2061 - accuracy: 0.9281 - val_loss: 0.2059 - val_accuracy: 0.9281\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.20595 to 0.20588, saving model to model_2.best_v4.hdf5\n",
      "Epoch 21/100\n",
      "919289/919289 [==============================] - 73s 80us/step - loss: 0.2061 - accuracy: 0.9281 - val_loss: 0.2061 - val_accuracy: 0.9279\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.20588\n",
      "Epoch 22/100\n",
      "919289/919289 [==============================] - 73s 79us/step - loss: 0.2059 - accuracy: 0.9282 - val_loss: 0.2060 - val_accuracy: 0.9281\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.20588\n",
      "Epoch 23/100\n",
      "919289/919289 [==============================] - 71s 77us/step - loss: 0.2059 - accuracy: 0.9283 - val_loss: 0.2059 - val_accuracy: 0.9282\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.20588\n",
      "Epoch 24/100\n",
      "919289/919289 [==============================] - 74s 80us/step - loss: 0.2058 - accuracy: 0.9282 - val_loss: 0.2061 - val_accuracy: 0.9280\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.20588\n",
      "Epoch 25/100\n",
      "919289/919289 [==============================] - 70s 76us/step - loss: 0.2058 - accuracy: 0.9281 - val_loss: 0.2061 - val_accuracy: 0.9280\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.20588\n",
      "Epoch 26/100\n",
      "919289/919289 [==============================] - 73s 79us/step - loss: 0.2058 - accuracy: 0.9282 - val_loss: 0.2061 - val_accuracy: 0.9282\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.20588\n",
      "Epoch 27/100\n",
      "919289/919289 [==============================] - 74s 80us/step - loss: 0.2057 - accuracy: 0.9282 - val_loss: 0.2061 - val_accuracy: 0.9281\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.20588\n",
      "Epoch 28/100\n",
      "919289/919289 [==============================] - 72s 78us/step - loss: 0.2056 - accuracy: 0.9282 - val_loss: 0.2064 - val_accuracy: 0.9277\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.20588\n",
      "Epoch 29/100\n",
      "919289/919289 [==============================] - 71s 78us/step - loss: 0.2056 - accuracy: 0.9281 - val_loss: 0.2061 - val_accuracy: 0.9280\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.20588\n",
      "Epoch 30/100\n",
      "919289/919289 [==============================] - 69s 75us/step - loss: 0.2055 - accuracy: 0.9283 - val_loss: 0.2066 - val_accuracy: 0.9279\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.20588\n",
      "Epoch 31/100\n",
      "919289/919289 [==============================] - 75s 82us/step - loss: 0.2054 - accuracy: 0.9283 - val_loss: 0.2060 - val_accuracy: 0.9279\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.20588\n",
      "Epoch 32/100\n",
      "919289/919289 [==============================] - 71s 78us/step - loss: 0.2053 - accuracy: 0.9283 - val_loss: 0.2058 - val_accuracy: 0.9282\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.20588 to 0.20583, saving model to model_2.best_v4.hdf5\n",
      "Epoch 33/100\n",
      "919289/919289 [==============================] - 73s 79us/step - loss: 0.2053 - accuracy: 0.9283 - val_loss: 0.2063 - val_accuracy: 0.9282\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.20583\n",
      "Epoch 34/100\n",
      "919289/919289 [==============================] - 73s 79us/step - loss: 0.2053 - accuracy: 0.9283 - val_loss: 0.2060 - val_accuracy: 0.9278\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.20583\n",
      "Epoch 35/100\n",
      "919289/919289 [==============================] - 73s 79us/step - loss: 0.2052 - accuracy: 0.9282 - val_loss: 0.2062 - val_accuracy: 0.9278\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.20583\n",
      "Epoch 36/100\n",
      "919289/919289 [==============================] - 71s 77us/step - loss: 0.2051 - accuracy: 0.9283 - val_loss: 0.2062 - val_accuracy: 0.9282\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.20583\n",
      "Epoch 37/100\n",
      "919289/919289 [==============================] - 73s 79us/step - loss: 0.2051 - accuracy: 0.9284 - val_loss: 0.2068 - val_accuracy: 0.9282\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.20583\n",
      "Epoch 38/100\n",
      "919289/919289 [==============================] - 74s 80us/step - loss: 0.2050 - accuracy: 0.9284 - val_loss: 0.2059 - val_accuracy: 0.9281\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.20583\n",
      "Epoch 39/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "919289/919289 [==============================] - 69s 75us/step - loss: 0.2050 - accuracy: 0.9283 - val_loss: 0.2062 - val_accuracy: 0.9281\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.20583\n",
      "Epoch 40/100\n",
      "919289/919289 [==============================] - 74s 81us/step - loss: 0.2048 - accuracy: 0.9284 - val_loss: 0.2067 - val_accuracy: 0.9278\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.20583\n",
      "Epoch 41/100\n",
      "919289/919289 [==============================] - 70s 76us/step - loss: 0.2048 - accuracy: 0.9284 - val_loss: 0.2061 - val_accuracy: 0.9281\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.20583\n",
      "Epoch 42/100\n",
      "919289/919289 [==============================] - 73s 80us/step - loss: 0.2048 - accuracy: 0.9282 - val_loss: 0.2060 - val_accuracy: 0.9281\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.20583\n",
      "Epoch 43/100\n",
      "919289/919289 [==============================] - 73s 79us/step - loss: 0.2048 - accuracy: 0.9284 - val_loss: 0.2062 - val_accuracy: 0.9282\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.20583\n",
      "Epoch 44/100\n",
      "919289/919289 [==============================] - 69s 75us/step - loss: 0.2047 - accuracy: 0.9284 - val_loss: 0.2065 - val_accuracy: 0.9281\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.20583\n",
      "Epoch 45/100\n",
      "919289/919289 [==============================] - 76s 83us/step - loss: 0.2046 - accuracy: 0.9284 - val_loss: 0.2061 - val_accuracy: 0.9281\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.20583\n",
      "Epoch 46/100\n",
      "919289/919289 [==============================] - 70s 77us/step - loss: 0.2045 - accuracy: 0.9284 - val_loss: 0.2061 - val_accuracy: 0.9282\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.20583\n",
      "Epoch 47/100\n",
      "919289/919289 [==============================] - 70s 76us/step - loss: 0.2046 - accuracy: 0.9284 - val_loss: 0.2064 - val_accuracy: 0.9280\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.20583\n",
      "Epoch 48/100\n",
      "919289/919289 [==============================] - 75s 81us/step - loss: 0.2046 - accuracy: 0.9283 - val_loss: 0.2062 - val_accuracy: 0.9281\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.20583\n",
      "Epoch 49/100\n",
      "919289/919289 [==============================] - 70s 76us/step - loss: 0.2044 - accuracy: 0.9285 - val_loss: 0.2063 - val_accuracy: 0.9281\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.20583\n",
      "Epoch 50/100\n",
      "919289/919289 [==============================] - 73s 79us/step - loss: 0.2043 - accuracy: 0.9284 - val_loss: 0.2064 - val_accuracy: 0.9281\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.20583\n",
      "Epoch 51/100\n",
      "919289/919289 [==============================] - 72s 78us/step - loss: 0.2043 - accuracy: 0.9284 - val_loss: 0.2066 - val_accuracy: 0.9282\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.20583\n",
      "Epoch 52/100\n",
      "919289/919289 [==============================] - 72s 78us/step - loss: 0.2043 - accuracy: 0.9284 - val_loss: 0.2065 - val_accuracy: 0.9280\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.20583\n",
      "Epoch 53/100\n",
      "919289/919289 [==============================] - 74s 81us/step - loss: 0.2042 - accuracy: 0.9284 - val_loss: 0.2064 - val_accuracy: 0.9282\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.20583\n",
      "Epoch 54/100\n",
      "919289/919289 [==============================] - 69s 75us/step - loss: 0.2041 - accuracy: 0.9286 - val_loss: 0.2065 - val_accuracy: 0.9280\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.20583\n",
      "Epoch 55/100\n",
      "919289/919289 [==============================] - 73s 80us/step - loss: 0.2040 - accuracy: 0.9286 - val_loss: 0.2065 - val_accuracy: 0.9280\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.20583\n",
      "Epoch 56/100\n",
      "919289/919289 [==============================] - 70s 76us/step - loss: 0.2040 - accuracy: 0.9286 - val_loss: 0.2063 - val_accuracy: 0.9280\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.20583\n",
      "Epoch 57/100\n",
      "919289/919289 [==============================] - 74s 81us/step - loss: 0.2039 - accuracy: 0.9285 - val_loss: 0.2063 - val_accuracy: 0.9280\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.20583\n",
      "Epoch 58/100\n",
      "919289/919289 [==============================] - 71s 78us/step - loss: 0.2038 - accuracy: 0.9287 - val_loss: 0.2066 - val_accuracy: 0.9280\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.20583\n",
      "Epoch 59/100\n",
      "919289/919289 [==============================] - 73s 79us/step - loss: 0.2040 - accuracy: 0.9285 - val_loss: 0.2064 - val_accuracy: 0.9280\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.20583\n",
      "Epoch 60/100\n",
      "919289/919289 [==============================] - 71s 77us/step - loss: 0.2039 - accuracy: 0.9285 - val_loss: 0.2069 - val_accuracy: 0.9281\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.20583\n",
      "Epoch 61/100\n",
      "919289/919289 [==============================] - 74s 80us/step - loss: 0.2038 - accuracy: 0.9285 - val_loss: 0.2066 - val_accuracy: 0.9281\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.20583\n",
      "Epoch 62/100\n",
      "919289/919289 [==============================] - 70s 76us/step - loss: 0.2038 - accuracy: 0.9285 - val_loss: 0.2065 - val_accuracy: 0.9282\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.20583\n",
      "Epoch 63/100\n",
      "919289/919289 [==============================] - 73s 80us/step - loss: 0.2036 - accuracy: 0.9286 - val_loss: 0.2063 - val_accuracy: 0.9280\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.20583\n",
      "Epoch 64/100\n",
      "919289/919289 [==============================] - 73s 79us/step - loss: 0.2037 - accuracy: 0.9286 - val_loss: 0.2063 - val_accuracy: 0.9281\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.20583\n",
      "Epoch 65/100\n",
      "919289/919289 [==============================] - 69s 76us/step - loss: 0.2037 - accuracy: 0.9285 - val_loss: 0.2066 - val_accuracy: 0.9281\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.20583\n",
      "Epoch 66/100\n",
      "919289/919289 [==============================] - 75s 82us/step - loss: 0.2037 - accuracy: 0.9286 - val_loss: 0.2068 - val_accuracy: 0.9280\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.20583\n",
      "Epoch 67/100\n",
      "919289/919289 [==============================] - 70s 76us/step - loss: 0.2035 - accuracy: 0.9286 - val_loss: 0.2066 - val_accuracy: 0.9281\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.20583\n",
      "Epoch 68/100\n",
      "919289/919289 [==============================] - 74s 80us/step - loss: 0.2035 - accuracy: 0.9287 - val_loss: 0.2065 - val_accuracy: 0.9280\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.20583\n",
      "Epoch 69/100\n",
      "919289/919289 [==============================] - 72s 78us/step - loss: 0.2035 - accuracy: 0.9286 - val_loss: 0.2064 - val_accuracy: 0.9281\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.20583\n",
      "Epoch 70/100\n",
      "919289/919289 [==============================] - 71s 78us/step - loss: 0.2033 - accuracy: 0.9287 - val_loss: 0.2068 - val_accuracy: 0.9280\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.20583\n",
      "Epoch 71/100\n",
      "919289/919289 [==============================] - 73s 80us/step - loss: 0.2032 - accuracy: 0.9287 - val_loss: 0.2066 - val_accuracy: 0.9282\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.20583\n",
      "Epoch 72/100\n",
      "919289/919289 [==============================] - 70s 76us/step - loss: 0.2033 - accuracy: 0.9287 - val_loss: 0.2064 - val_accuracy: 0.9281\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.20583\n",
      "Epoch 73/100\n",
      "919289/919289 [==============================] - 75s 82us/step - loss: 0.2031 - accuracy: 0.9288 - val_loss: 0.2064 - val_accuracy: 0.9281\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.20583\n",
      "Epoch 74/100\n",
      "919289/919289 [==============================] - 71s 77us/step - loss: 0.2031 - accuracy: 0.9287 - val_loss: 0.2064 - val_accuracy: 0.9280\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.20583\n",
      "Epoch 75/100\n",
      "919289/919289 [==============================] - 73s 80us/step - loss: 0.2032 - accuracy: 0.9287 - val_loss: 0.2069 - val_accuracy: 0.9281\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.20583\n",
      "Epoch 76/100\n",
      "919289/919289 [==============================] - 71s 77us/step - loss: 0.2031 - accuracy: 0.9287 - val_loss: 0.2067 - val_accuracy: 0.9283\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.20583\n",
      "Epoch 77/100\n",
      "919289/919289 [==============================] - 73s 79us/step - loss: 0.2030 - accuracy: 0.9289 - val_loss: 0.2064 - val_accuracy: 0.9281\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.20583\n",
      "Epoch 78/100\n",
      "919289/919289 [==============================] - 73s 79us/step - loss: 0.2030 - accuracy: 0.9287 - val_loss: 0.2065 - val_accuracy: 0.9281\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.20583\n",
      "Epoch 79/100\n",
      "919289/919289 [==============================] - 71s 77us/step - loss: 0.2030 - accuracy: 0.9289 - val_loss: 0.2066 - val_accuracy: 0.9280\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.20583\n",
      "Epoch 80/100\n",
      "919289/919289 [==============================] - 73s 79us/step - loss: 0.2029 - accuracy: 0.9288 - val_loss: 0.2076 - val_accuracy: 0.9278\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.20583\n",
      "Epoch 81/100\n",
      "919289/919289 [==============================] - 69s 75us/step - loss: 0.2028 - accuracy: 0.9290 - val_loss: 0.2066 - val_accuracy: 0.9282\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.20583\n",
      "Epoch 82/100\n",
      "919289/919289 [==============================] - 74s 80us/step - loss: 0.2028 - accuracy: 0.9288 - val_loss: 0.2065 - val_accuracy: 0.9279\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 0.20583\n",
      "Epoch 83/100\n",
      "919289/919289 [==============================] - 71s 77us/step - loss: 0.2028 - accuracy: 0.9289 - val_loss: 0.2067 - val_accuracy: 0.9282\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 0.20583\n",
      "Epoch 84/100\n",
      "919289/919289 [==============================] - 73s 79us/step - loss: 0.2027 - accuracy: 0.9287 - val_loss: 0.2070 - val_accuracy: 0.9280\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.20583\n",
      "Epoch 85/100\n",
      "919289/919289 [==============================] - 70s 76us/step - loss: 0.2027 - accuracy: 0.9287 - val_loss: 0.2069 - val_accuracy: 0.9282\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.20583\n",
      "Epoch 86/100\n",
      "919289/919289 [==============================] - 73s 79us/step - loss: 0.2026 - accuracy: 0.9289 - val_loss: 0.2068 - val_accuracy: 0.9281\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.20583\n",
      "Epoch 87/100\n",
      "919289/919289 [==============================] - 74s 81us/step - loss: 0.2026 - accuracy: 0.9289 - val_loss: 0.2067 - val_accuracy: 0.9280\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.20583\n",
      "Epoch 88/100\n",
      "919289/919289 [==============================] - 69s 75us/step - loss: 0.2025 - accuracy: 0.9288 - val_loss: 0.2068 - val_accuracy: 0.9280\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 0.20583\n",
      "Epoch 89/100\n",
      "919289/919289 [==============================] - 74s 80us/step - loss: 0.2026 - accuracy: 0.9288 - val_loss: 0.2067 - val_accuracy: 0.9282\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 0.20583\n",
      "Epoch 90/100\n",
      "919289/919289 [==============================] - 71s 77us/step - loss: 0.2024 - accuracy: 0.9290 - val_loss: 0.2066 - val_accuracy: 0.9281\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.20583\n",
      "Epoch 91/100\n",
      "919289/919289 [==============================] - 72s 78us/step - loss: 0.2025 - accuracy: 0.9290 - val_loss: 0.2070 - val_accuracy: 0.9280\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.20583\n",
      "Epoch 92/100\n",
      "919289/919289 [==============================] - 75s 82us/step - loss: 0.2024 - accuracy: 0.9290 - val_loss: 0.2073 - val_accuracy: 0.9281\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.20583\n",
      "Epoch 93/100\n",
      "919289/919289 [==============================] - 69s 75us/step - loss: 0.2023 - accuracy: 0.9290 - val_loss: 0.2068 - val_accuracy: 0.9281\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.20583\n",
      "Epoch 94/100\n",
      "919289/919289 [==============================] - 74s 81us/step - loss: 0.2023 - accuracy: 0.9289 - val_loss: 0.2069 - val_accuracy: 0.9281\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 0.20583\n",
      "Epoch 95/100\n",
      "919289/919289 [==============================] - 70s 76us/step - loss: 0.2023 - accuracy: 0.9290 - val_loss: 0.2069 - val_accuracy: 0.9281\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.20583\n",
      "Epoch 96/100\n",
      "919289/919289 [==============================] - 70s 76us/step - loss: 0.2021 - accuracy: 0.9289 - val_loss: 0.2069 - val_accuracy: 0.9281\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 0.20583\n",
      "Epoch 97/100\n",
      "919289/919289 [==============================] - 74s 80us/step - loss: 0.2021 - accuracy: 0.9291 - val_loss: 0.2068 - val_accuracy: 0.9282\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 0.20583\n",
      "Epoch 98/100\n",
      "919289/919289 [==============================] - 72s 79us/step - loss: 0.2021 - accuracy: 0.9291 - val_loss: 0.2072 - val_accuracy: 0.9281\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.20583\n",
      "Epoch 99/100\n",
      "919289/919289 [==============================] - 71s 78us/step - loss: 0.2021 - accuracy: 0.9290 - val_loss: 0.2070 - val_accuracy: 0.9282\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 0.20583\n",
      "Epoch 100/100\n",
      "919289/919289 [==============================] - 73s 79us/step - loss: 0.2020 - accuracy: 0.9291 - val_loss: 0.2069 - val_accuracy: 0.9282\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 0.20583\n",
      "1178576/1178576 [==============================] - 29s 25us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|███████████████████████████████▏                                              | 2/5 [4:04:39<6:08:55, 7378.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 919290 samples, validate on 229822 samples\n",
      "Epoch 1/100\n",
      "919290/919290 [==============================] - 75s 82us/step - loss: 0.2373 - accuracy: 0.9208 - val_loss: 0.2092 - val_accuracy: 0.9274\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.20925, saving model to model_3.best_v4.hdf5\n",
      "Epoch 2/100\n",
      "919290/919290 [==============================] - 69s 75us/step - loss: 0.2097 - accuracy: 0.9275 - val_loss: 0.2080 - val_accuracy: 0.9278\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.20925 to 0.20797, saving model to model_3.best_v4.hdf5\n",
      "Epoch 3/100\n",
      "919290/919290 [==============================] - 72s 78us/step - loss: 0.2086 - accuracy: 0.9276 - val_loss: 0.2094 - val_accuracy: 0.9263\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.20797\n",
      "Epoch 4/100\n",
      "919290/919290 [==============================] - 75s 82us/step - loss: 0.2081 - accuracy: 0.9276 - val_loss: 0.2095 - val_accuracy: 0.9267\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.20797\n",
      "Epoch 5/100\n",
      "919290/919290 [==============================] - 69s 75us/step - loss: 0.2076 - accuracy: 0.9278 - val_loss: 0.2075 - val_accuracy: 0.9277\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.20797 to 0.20754, saving model to model_3.best_v4.hdf5\n",
      "Epoch 6/100\n",
      "919290/919290 [==============================] - 69s 75us/step - loss: 0.2074 - accuracy: 0.9278 - val_loss: 0.2082 - val_accuracy: 0.9268\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.20754\n",
      "Epoch 7/100\n",
      "919290/919290 [==============================] - 76s 82us/step - loss: 0.2072 - accuracy: 0.9278 - val_loss: 0.2067 - val_accuracy: 0.9277\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.20754 to 0.20670, saving model to model_3.best_v4.hdf5\n",
      "Epoch 8/100\n",
      "919290/919290 [==============================] - 70s 76us/step - loss: 0.2071 - accuracy: 0.9278 - val_loss: 0.2074 - val_accuracy: 0.9271\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.20670\n",
      "Epoch 9/100\n",
      "919290/919290 [==============================] - 71s 78us/step - loss: 0.2070 - accuracy: 0.9279 - val_loss: 0.2095 - val_accuracy: 0.9249\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.20670\n",
      "Epoch 10/100\n",
      "919290/919290 [==============================] - 70s 77us/step - loss: 0.2068 - accuracy: 0.9278 - val_loss: 0.2081 - val_accuracy: 0.9266\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.20670\n",
      "Epoch 11/100\n",
      "919290/919290 [==============================] - 74s 81us/step - loss: 0.2067 - accuracy: 0.9279 - val_loss: 0.2065 - val_accuracy: 0.9278\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.20670 to 0.20651, saving model to model_3.best_v4.hdf5\n",
      "Epoch 12/100\n",
      "919290/919290 [==============================] - 68s 74us/step - loss: 0.2066 - accuracy: 0.9280 - val_loss: 0.2066 - val_accuracy: 0.9277\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.20651\n",
      "Epoch 13/100\n",
      "919290/919290 [==============================] - 75s 82us/step - loss: 0.2066 - accuracy: 0.9279 - val_loss: 0.2068 - val_accuracy: 0.9277\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.20651\n",
      "Epoch 14/100\n",
      "919290/919290 [==============================] - 69s 75us/step - loss: 0.2064 - accuracy: 0.9280 - val_loss: 0.2065 - val_accuracy: 0.9279\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.20651 to 0.20649, saving model to model_3.best_v4.hdf5\n",
      "Epoch 15/100\n",
      "919290/919290 [==============================] - 72s 78us/step - loss: 0.2064 - accuracy: 0.9280 - val_loss: 0.2071 - val_accuracy: 0.9273\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.20649\n",
      "Epoch 16/100\n",
      "919290/919290 [==============================] - 74s 80us/step - loss: 0.2064 - accuracy: 0.9280 - val_loss: 0.2064 - val_accuracy: 0.9279\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.20649 to 0.20637, saving model to model_3.best_v4.hdf5\n",
      "Epoch 17/100\n",
      "919290/919290 [==============================] - 68s 74us/step - loss: 0.2063 - accuracy: 0.9279 - val_loss: 0.2064 - val_accuracy: 0.9279\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.20637\n",
      "Epoch 18/100\n",
      "919290/919290 [==============================] - 74s 81us/step - loss: 0.2062 - accuracy: 0.9280 - val_loss: 0.2066 - val_accuracy: 0.9279\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.20637\n",
      "Epoch 19/100\n",
      "919290/919290 [==============================] - 70s 76us/step - loss: 0.2061 - accuracy: 0.9281 - val_loss: 0.2068 - val_accuracy: 0.9274\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.20637\n",
      "Epoch 20/100\n",
      "919290/919290 [==============================] - 74s 80us/step - loss: 0.2060 - accuracy: 0.9281 - val_loss: 0.2062 - val_accuracy: 0.9279\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.20637 to 0.20617, saving model to model_3.best_v4.hdf5\n",
      "Epoch 21/100\n",
      "919290/919290 [==============================] - 70s 76us/step - loss: 0.2060 - accuracy: 0.9281 - val_loss: 0.2064 - val_accuracy: 0.9278\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.20617\n",
      "Epoch 22/100\n",
      "919290/919290 [==============================] - 72s 78us/step - loss: 0.2060 - accuracy: 0.9280 - val_loss: 0.2072 - val_accuracy: 0.9272\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.20617\n",
      "Epoch 23/100\n",
      "919290/919290 [==============================] - 73s 79us/step - loss: 0.2059 - accuracy: 0.9282 - val_loss: 0.2062 - val_accuracy: 0.9279\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.20617\n",
      "Epoch 24/100\n",
      "919290/919290 [==============================] - 69s 75us/step - loss: 0.2059 - accuracy: 0.9280 - val_loss: 0.2062 - val_accuracy: 0.9280\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.20617 to 0.20615, saving model to model_3.best_v4.hdf5\n",
      "Epoch 25/100\n",
      "919290/919290 [==============================] - 75s 81us/step - loss: 0.2057 - accuracy: 0.9282 - val_loss: 0.2065 - val_accuracy: 0.9278\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.20615\n",
      "Epoch 26/100\n",
      "919290/919290 [==============================] - 68s 74us/step - loss: 0.2057 - accuracy: 0.9281 - val_loss: 0.2065 - val_accuracy: 0.9278\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.20615\n",
      "Epoch 27/100\n",
      "919290/919290 [==============================] - 73s 79us/step - loss: 0.2056 - accuracy: 0.9282 - val_loss: 0.2079 - val_accuracy: 0.9274\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.20615\n",
      "Epoch 28/100\n",
      "919290/919290 [==============================] - 72s 78us/step - loss: 0.2055 - accuracy: 0.9283 - val_loss: 0.2063 - val_accuracy: 0.9279\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.20615\n",
      "Epoch 29/100\n",
      "919290/919290 [==============================] - 72s 78us/step - loss: 0.2056 - accuracy: 0.9282 - val_loss: 0.2071 - val_accuracy: 0.9278\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.20615\n",
      "Epoch 30/100\n",
      "919290/919290 [==============================] - 73s 79us/step - loss: 0.2055 - accuracy: 0.9281 - val_loss: 0.2064 - val_accuracy: 0.9278\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.20615\n",
      "Epoch 31/100\n",
      "919290/919290 [==============================] - 71s 77us/step - loss: 0.2053 - accuracy: 0.9281 - val_loss: 0.2067 - val_accuracy: 0.9277\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.20615\n",
      "Epoch 32/100\n",
      "919290/919290 [==============================] - 72s 78us/step - loss: 0.2053 - accuracy: 0.9282 - val_loss: 0.2065 - val_accuracy: 0.9277\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.20615\n",
      "Epoch 33/100\n",
      "919290/919290 [==============================] - 71s 77us/step - loss: 0.2053 - accuracy: 0.9282 - val_loss: 0.2065 - val_accuracy: 0.9279\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.20615\n",
      "Epoch 34/100\n",
      "919290/919290 [==============================] - 73s 80us/step - loss: 0.2052 - accuracy: 0.9282 - val_loss: 0.2063 - val_accuracy: 0.9279\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.20615\n",
      "Epoch 35/100\n",
      "919290/919290 [==============================] - 69s 75us/step - loss: 0.2052 - accuracy: 0.9283 - val_loss: 0.2062 - val_accuracy: 0.9279\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.20615\n",
      "Epoch 36/100\n",
      "919290/919290 [==============================] - 76s 83us/step - loss: 0.2051 - accuracy: 0.9284 - val_loss: 0.2067 - val_accuracy: 0.9278\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.20615\n",
      "Epoch 37/100\n",
      "919290/919290 [==============================] - 68s 74us/step - loss: 0.2050 - accuracy: 0.9283 - val_loss: 0.2068 - val_accuracy: 0.9276\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.20615\n",
      "Epoch 38/100\n",
      "919290/919290 [==============================] - 74s 80us/step - loss: 0.2049 - accuracy: 0.9283 - val_loss: 0.2065 - val_accuracy: 0.9280\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.20615\n",
      "Epoch 39/100\n",
      "919290/919290 [==============================] - 71s 77us/step - loss: 0.2050 - accuracy: 0.9284 - val_loss: 0.2064 - val_accuracy: 0.9280\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.20615\n",
      "Epoch 40/100\n",
      "919290/919290 [==============================] - 71s 77us/step - loss: 0.2048 - accuracy: 0.9285 - val_loss: 0.2064 - val_accuracy: 0.9280\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.20615\n",
      "Epoch 41/100\n",
      "919290/919290 [==============================] - 74s 80us/step - loss: 0.2049 - accuracy: 0.9284 - val_loss: 0.2063 - val_accuracy: 0.9280\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.20615\n",
      "Epoch 42/100\n",
      "919290/919290 [==============================] - 68s 74us/step - loss: 0.2047 - accuracy: 0.9284 - val_loss: 0.2065 - val_accuracy: 0.9279\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.20615\n",
      "Epoch 43/100\n",
      "919290/919290 [==============================] - 77s 83us/step - loss: 0.2046 - accuracy: 0.9284 - val_loss: 0.2080 - val_accuracy: 0.9277\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.20615\n",
      "Epoch 44/100\n",
      "919290/919290 [==============================] - 72s 78us/step - loss: 0.2045 - accuracy: 0.9284 - val_loss: 0.2066 - val_accuracy: 0.9279\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.20615\n",
      "Epoch 45/100\n",
      "919290/919290 [==============================] - 71s 77us/step - loss: 0.2045 - accuracy: 0.9285 - val_loss: 0.2064 - val_accuracy: 0.9280\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.20615\n",
      "Epoch 46/100\n",
      "919290/919290 [==============================] - 70s 76us/step - loss: 0.2046 - accuracy: 0.9284 - val_loss: 0.2063 - val_accuracy: 0.9280\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.20615\n",
      "Epoch 47/100\n",
      "919290/919290 [==============================] - 75s 81us/step - loss: 0.2044 - accuracy: 0.9283 - val_loss: 0.2065 - val_accuracy: 0.9280\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.20615\n",
      "Epoch 48/100\n",
      "919290/919290 [==============================] - 69s 75us/step - loss: 0.2044 - accuracy: 0.9285 - val_loss: 0.2064 - val_accuracy: 0.9279\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.20615\n",
      "Epoch 49/100\n",
      "919290/919290 [==============================] - 73s 80us/step - loss: 0.2043 - accuracy: 0.9285 - val_loss: 0.2066 - val_accuracy: 0.9280\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.20615\n",
      "Epoch 50/100\n",
      "919290/919290 [==============================] - 71s 78us/step - loss: 0.2043 - accuracy: 0.9286 - val_loss: 0.2065 - val_accuracy: 0.9277\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.20615\n",
      "Epoch 51/100\n",
      "919290/919290 [==============================] - 69s 75us/step - loss: 0.2042 - accuracy: 0.9286 - val_loss: 0.2066 - val_accuracy: 0.9279\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.20615\n",
      "Epoch 52/100\n",
      "919290/919290 [==============================] - 75s 82us/step - loss: 0.2042 - accuracy: 0.9287 - val_loss: 0.2070 - val_accuracy: 0.9280\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.20615\n",
      "Epoch 53/100\n",
      "919290/919290 [==============================] - 70s 76us/step - loss: 0.2042 - accuracy: 0.9286 - val_loss: 0.2069 - val_accuracy: 0.9280\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.20615\n",
      "Epoch 54/100\n",
      "919290/919290 [==============================] - 73s 79us/step - loss: 0.2039 - accuracy: 0.9285 - val_loss: 0.2067 - val_accuracy: 0.9280\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.20615\n",
      "Epoch 55/100\n",
      "919290/919290 [==============================] - 72s 79us/step - loss: 0.2040 - accuracy: 0.9285 - val_loss: 0.2065 - val_accuracy: 0.9280\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.20615\n",
      "Epoch 56/100\n",
      "919290/919290 [==============================] - 71s 78us/step - loss: 0.2040 - accuracy: 0.9286 - val_loss: 0.2068 - val_accuracy: 0.9278\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.20615\n",
      "Epoch 57/100\n",
      "919290/919290 [==============================] - 71s 77us/step - loss: 0.2038 - accuracy: 0.9286 - val_loss: 0.2066 - val_accuracy: 0.9280\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.20615\n",
      "Epoch 58/100\n",
      "919290/919290 [==============================] - 70s 76us/step - loss: 0.2038 - accuracy: 0.9286 - val_loss: 0.2066 - val_accuracy: 0.9280\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.20615\n",
      "Epoch 59/100\n",
      "919290/919290 [==============================] - 74s 80us/step - loss: 0.2038 - accuracy: 0.9287 - val_loss: 0.2065 - val_accuracy: 0.9280\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.20615\n",
      "Epoch 60/100\n",
      "919290/919290 [==============================] - 70s 76us/step - loss: 0.2037 - accuracy: 0.9286 - val_loss: 0.2071 - val_accuracy: 0.9280\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.20615\n",
      "Epoch 61/100\n",
      "919290/919290 [==============================] - 72s 78us/step - loss: 0.2037 - accuracy: 0.9287 - val_loss: 0.2068 - val_accuracy: 0.9280\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.20615\n",
      "Epoch 62/100\n",
      "919290/919290 [==============================] - 72s 79us/step - loss: 0.2037 - accuracy: 0.9285 - val_loss: 0.2065 - val_accuracy: 0.9281\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.20615\n",
      "Epoch 63/100\n",
      "919290/919290 [==============================] - 71s 78us/step - loss: 0.2038 - accuracy: 0.9287 - val_loss: 0.2064 - val_accuracy: 0.9280\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.20615\n",
      "Epoch 64/100\n",
      "919290/919290 [==============================] - 74s 80us/step - loss: 0.2035 - accuracy: 0.9287 - val_loss: 0.2069 - val_accuracy: 0.9282\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.20615\n",
      "Epoch 65/100\n",
      "919290/919290 [==============================] - 69s 75us/step - loss: 0.2035 - accuracy: 0.9288 - val_loss: 0.2067 - val_accuracy: 0.9280\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.20615\n",
      "Epoch 66/100\n",
      "919290/919290 [==============================] - 74s 81us/step - loss: 0.2034 - accuracy: 0.9287 - val_loss: 0.2071 - val_accuracy: 0.9279\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.20615\n",
      "Epoch 67/100\n",
      "919290/919290 [==============================] - 70s 76us/step - loss: 0.2033 - accuracy: 0.9287 - val_loss: 0.2070 - val_accuracy: 0.9280\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.20615\n",
      "Epoch 68/100\n",
      "919290/919290 [==============================] - 75s 81us/step - loss: 0.2034 - accuracy: 0.9287 - val_loss: 0.2068 - val_accuracy: 0.9280\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.20615\n",
      "Epoch 69/100\n",
      "919290/919290 [==============================] - 69s 75us/step - loss: 0.2034 - accuracy: 0.9287 - val_loss: 0.2066 - val_accuracy: 0.9281\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.20615\n",
      "Epoch 70/100\n",
      "919290/919290 [==============================] - 72s 78us/step - loss: 0.2032 - accuracy: 0.9287 - val_loss: 0.2071 - val_accuracy: 0.9281\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.20615\n",
      "Epoch 71/100\n",
      "919290/919290 [==============================] - 73s 79us/step - loss: 0.2032 - accuracy: 0.9287 - val_loss: 0.2069 - val_accuracy: 0.9279\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.20615\n",
      "Epoch 72/100\n",
      "919290/919290 [==============================] - 69s 75us/step - loss: 0.2031 - accuracy: 0.9288 - val_loss: 0.2068 - val_accuracy: 0.9280\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.20615\n",
      "Epoch 73/100\n",
      "919290/919290 [==============================] - 74s 81us/step - loss: 0.2031 - accuracy: 0.9288 - val_loss: 0.2068 - val_accuracy: 0.9280\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.20615\n",
      "Epoch 74/100\n",
      "919290/919290 [==============================] - 69s 75us/step - loss: 0.2031 - accuracy: 0.9287 - val_loss: 0.2070 - val_accuracy: 0.9281\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.20615\n",
      "Epoch 75/100\n",
      "919290/919290 [==============================] - 73s 80us/step - loss: 0.2031 - accuracy: 0.9288 - val_loss: 0.2073 - val_accuracy: 0.9281\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.20615\n",
      "Epoch 76/100\n",
      "919290/919290 [==============================] - 71s 77us/step - loss: 0.2031 - accuracy: 0.9287 - val_loss: 0.2070 - val_accuracy: 0.9282\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.20615\n",
      "Epoch 77/100\n",
      "919290/919290 [==============================] - 71s 78us/step - loss: 0.2030 - accuracy: 0.9287 - val_loss: 0.2068 - val_accuracy: 0.9280\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.20615\n",
      "Epoch 78/100\n",
      "919290/919290 [==============================] - 72s 78us/step - loss: 0.2029 - accuracy: 0.9288 - val_loss: 0.2075 - val_accuracy: 0.9281\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.20615\n",
      "Epoch 79/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "919290/919290 [==============================] - 70s 76us/step - loss: 0.2030 - accuracy: 0.9290 - val_loss: 0.2067 - val_accuracy: 0.9279\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.20615\n",
      "Epoch 80/100\n",
      "919290/919290 [==============================] - 73s 79us/step - loss: 0.2028 - accuracy: 0.9289 - val_loss: 0.2069 - val_accuracy: 0.9281\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.20615\n",
      "Epoch 81/100\n",
      "919290/919290 [==============================] - 72s 79us/step - loss: 0.2028 - accuracy: 0.9288 - val_loss: 0.2072 - val_accuracy: 0.9282\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.20615\n",
      "Epoch 82/100\n",
      "919290/919290 [==============================] - 72s 79us/step - loss: 0.2027 - accuracy: 0.9289 - val_loss: 0.2069 - val_accuracy: 0.9280\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 0.20615\n",
      "Epoch 83/100\n",
      "919290/919290 [==============================] - 69s 76us/step - loss: 0.2028 - accuracy: 0.9289 - val_loss: 0.2069 - val_accuracy: 0.9282\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 0.20615\n",
      "Epoch 84/100\n",
      "919290/919290 [==============================] - 71s 77us/step - loss: 0.2027 - accuracy: 0.9288 - val_loss: 0.2069 - val_accuracy: 0.9281\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.20615\n",
      "Epoch 85/100\n",
      "919290/919290 [==============================] - 72s 78us/step - loss: 0.2026 - accuracy: 0.9289 - val_loss: 0.2071 - val_accuracy: 0.9281\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.20615\n",
      "Epoch 86/100\n",
      "919290/919290 [==============================] - 73s 79us/step - loss: 0.2026 - accuracy: 0.9289 - val_loss: 0.2068 - val_accuracy: 0.9281\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.20615\n",
      "Epoch 87/100\n",
      "919290/919290 [==============================] - 71s 77us/step - loss: 0.2025 - accuracy: 0.9289 - val_loss: 0.2070 - val_accuracy: 0.9280\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.20615\n",
      "Epoch 88/100\n",
      "919290/919290 [==============================] - 72s 78us/step - loss: 0.2026 - accuracy: 0.9288 - val_loss: 0.2070 - val_accuracy: 0.9282\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 0.20615\n",
      "Epoch 89/100\n",
      "919290/919290 [==============================] - 69s 75us/step - loss: 0.2026 - accuracy: 0.9289 - val_loss: 0.2069 - val_accuracy: 0.9281\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 0.20615\n",
      "Epoch 90/100\n",
      "919290/919290 [==============================] - 73s 79us/step - loss: 0.2024 - accuracy: 0.9290 - val_loss: 0.2073 - val_accuracy: 0.9281\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.20615\n",
      "Epoch 91/100\n",
      "919290/919290 [==============================] - 71s 77us/step - loss: 0.2024 - accuracy: 0.9290 - val_loss: 0.2070 - val_accuracy: 0.9281\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.20615\n",
      "Epoch 92/100\n",
      "919290/919290 [==============================] - 73s 79us/step - loss: 0.2025 - accuracy: 0.9287 - val_loss: 0.2071 - val_accuracy: 0.9281\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.20615\n",
      "Epoch 93/100\n",
      "919290/919290 [==============================] - 70s 76us/step - loss: 0.2023 - accuracy: 0.9290 - val_loss: 0.2072 - val_accuracy: 0.9282\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.20615\n",
      "Epoch 94/100\n",
      "919290/919290 [==============================] - 73s 79us/step - loss: 0.2022 - accuracy: 0.9290 - val_loss: 0.2074 - val_accuracy: 0.9276\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 0.20615\n",
      "Epoch 95/100\n",
      "919290/919290 [==============================] - 73s 79us/step - loss: 0.2022 - accuracy: 0.9289 - val_loss: 0.2071 - val_accuracy: 0.9279\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.20615\n",
      "Epoch 96/100\n",
      "919290/919290 [==============================] - 70s 76us/step - loss: 0.2022 - accuracy: 0.9290 - val_loss: 0.2077 - val_accuracy: 0.9281\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 0.20615\n",
      "Epoch 97/100\n",
      "919290/919290 [==============================] - 74s 81us/step - loss: 0.2022 - accuracy: 0.9291 - val_loss: 0.2082 - val_accuracy: 0.9272\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 0.20615\n",
      "Epoch 98/100\n",
      "919290/919290 [==============================] - 69s 75us/step - loss: 0.2021 - accuracy: 0.9289 - val_loss: 0.2070 - val_accuracy: 0.9282\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.20615\n",
      "Epoch 99/100\n",
      "919290/919290 [==============================] - 73s 80us/step - loss: 0.2021 - accuracy: 0.9290 - val_loss: 0.2075 - val_accuracy: 0.9282\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 0.20615\n",
      "Epoch 100/100\n",
      "919290/919290 [==============================] - 70s 76us/step - loss: 0.2020 - accuracy: 0.9289 - val_loss: 0.2071 - val_accuracy: 0.9281\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 0.20615\n",
      "1178576/1178576 [==============================] - 31s 26us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|██████████████████████████████████████████████▊                               | 3/5 [6:04:43<4:04:12, 7326.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 919290 samples, validate on 229822 samples\n",
      "Epoch 1/100\n",
      "919290/919290 [==============================] - 75s 82us/step - loss: 0.2361 - accuracy: 0.9218 - val_loss: 0.2095 - val_accuracy: 0.9281\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.20947, saving model to model_4.best_v4.hdf5\n",
      "Epoch 2/100\n",
      "919290/919290 [==============================] - 71s 77us/step - loss: 0.2099 - accuracy: 0.9272 - val_loss: 0.2082 - val_accuracy: 0.9282\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.20947 to 0.20822, saving model to model_4.best_v4.hdf5\n",
      "Epoch 3/100\n",
      "919290/919290 [==============================] - 72s 79us/step - loss: 0.2088 - accuracy: 0.9274 - val_loss: 0.2076 - val_accuracy: 0.9276\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.20822 to 0.20763, saving model to model_4.best_v4.hdf5\n",
      "Epoch 4/100\n",
      "919290/919290 [==============================] - 71s 78us/step - loss: 0.2081 - accuracy: 0.9276 - val_loss: 0.2068 - val_accuracy: 0.9282\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.20763 to 0.20683, saving model to model_4.best_v4.hdf5\n",
      "Epoch 5/100\n",
      "919290/919290 [==============================] - 71s 77us/step - loss: 0.2078 - accuracy: 0.9275 - val_loss: 0.2093 - val_accuracy: 0.9251\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.20683\n",
      "Epoch 6/100\n",
      "919290/919290 [==============================] - 70s 76us/step - loss: 0.2075 - accuracy: 0.9276 - val_loss: 0.2066 - val_accuracy: 0.9283\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.20683 to 0.20658, saving model to model_4.best_v4.hdf5\n",
      "Epoch 7/100\n",
      "919290/919290 [==============================] - 75s 82us/step - loss: 0.2073 - accuracy: 0.9276 - val_loss: 0.2065 - val_accuracy: 0.9284\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.20658 to 0.20646, saving model to model_4.best_v4.hdf5\n",
      "Epoch 8/100\n",
      "919290/919290 [==============================] - 68s 74us/step - loss: 0.2071 - accuracy: 0.9277 - val_loss: 0.2067 - val_accuracy: 0.9278\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.20646\n",
      "Epoch 9/100\n",
      "919290/919290 [==============================] - 70s 76us/step - loss: 0.2070 - accuracy: 0.9278 - val_loss: 0.2108 - val_accuracy: 0.9251\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.20646\n",
      "Epoch 10/100\n",
      "919290/919290 [==============================] - 73s 79us/step - loss: 0.2070 - accuracy: 0.9276 - val_loss: 0.2083 - val_accuracy: 0.9269\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.20646\n",
      "Epoch 11/100\n",
      "919290/919290 [==============================] - 70s 76us/step - loss: 0.2068 - accuracy: 0.9278 - val_loss: 0.2063 - val_accuracy: 0.9282\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.20646 to 0.20632, saving model to model_4.best_v4.hdf5\n",
      "Epoch 12/100\n",
      "919290/919290 [==============================] - 75s 82us/step - loss: 0.2067 - accuracy: 0.9277 - val_loss: 0.2060 - val_accuracy: 0.9285\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.20632 to 0.20597, saving model to model_4.best_v4.hdf5\n",
      "Epoch 13/100\n",
      "919290/919290 [==============================] - 69s 75us/step - loss: 0.2067 - accuracy: 0.9278 - val_loss: 0.2060 - val_accuracy: 0.9285\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.20597\n",
      "Epoch 14/100\n",
      "919290/919290 [==============================] - 72s 79us/step - loss: 0.2065 - accuracy: 0.9278 - val_loss: 0.2061 - val_accuracy: 0.9282\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.20597\n",
      "Epoch 15/100\n",
      "919290/919290 [==============================] - 75s 81us/step - loss: 0.2064 - accuracy: 0.9279 - val_loss: 0.2080 - val_accuracy: 0.9271\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.20597\n",
      "Epoch 16/100\n",
      "919290/919290 [==============================] - 68s 74us/step - loss: 0.2064 - accuracy: 0.9278 - val_loss: 0.2064 - val_accuracy: 0.9285\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.20597\n",
      "Epoch 17/100\n",
      "919290/919290 [==============================] - 74s 81us/step - loss: 0.2064 - accuracy: 0.9278 - val_loss: 0.2061 - val_accuracy: 0.9285\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.20597\n",
      "Epoch 18/100\n",
      "919290/919290 [==============================] - 68s 74us/step - loss: 0.2061 - accuracy: 0.9279 - val_loss: 0.2059 - val_accuracy: 0.9285\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.20597 to 0.20595, saving model to model_4.best_v4.hdf5\n",
      "Epoch 19/100\n",
      "919290/919290 [==============================] - 74s 80us/step - loss: 0.2061 - accuracy: 0.9278 - val_loss: 0.2060 - val_accuracy: 0.9285 loss: 0.2061 - accuracy: \n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.20595\n",
      "Epoch 20/100\n",
      "919290/919290 [==============================] - 73s 79us/step - loss: 0.2061 - accuracy: 0.9279 - val_loss: 0.2060 - val_accuracy: 0.9287\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.20595\n",
      "Epoch 21/100\n",
      "919290/919290 [==============================] - 71s 77us/step - loss: 0.2059 - accuracy: 0.9279 - val_loss: 0.2061 - val_accuracy: 0.9287\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.20595\n",
      "Epoch 22/100\n",
      "919290/919290 [==============================] - 72s 79us/step - loss: 0.2060 - accuracy: 0.9279 - val_loss: 0.2069 - val_accuracy: 0.9280\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.20595\n",
      "Epoch 23/100\n",
      "919290/919290 [==============================] - 72s 78us/step - loss: 0.2059 - accuracy: 0.9279 - val_loss: 0.2062 - val_accuracy: 0.9285\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.20595\n",
      "Epoch 24/100\n",
      "919290/919290 [==============================] - 73s 79us/step - loss: 0.2058 - accuracy: 0.9281 - val_loss: 0.2061 - val_accuracy: 0.9285\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.20595\n",
      "Epoch 25/100\n",
      "919290/919290 [==============================] - 72s 79us/step - loss: 0.2057 - accuracy: 0.9280 - val_loss: 0.2063 - val_accuracy: 0.9281\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.20595\n",
      "Epoch 26/100\n",
      "919290/919290 [==============================] - 70s 76us/step - loss: 0.2057 - accuracy: 0.9280 - val_loss: 0.2066 - val_accuracy: 0.9285\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.20595\n",
      "Epoch 27/100\n",
      "919290/919290 [==============================] - 72s 78us/step - loss: 0.2055 - accuracy: 0.9282 - val_loss: 0.2061 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.20595\n",
      "Epoch 28/100\n",
      "919290/919290 [==============================] - 71s 77us/step - loss: 0.2055 - accuracy: 0.9280 - val_loss: 0.2062 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.20595\n",
      "Epoch 29/100\n",
      "919290/919290 [==============================] - 72s 79us/step - loss: 0.2056 - accuracy: 0.9281 - val_loss: 0.2063 - val_accuracy: 0.9283\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.20595\n",
      "Epoch 30/100\n",
      "919290/919290 [==============================] - 70s 76us/step - loss: 0.2054 - accuracy: 0.9282 - val_loss: 0.2062 - val_accuracy: 0.9285\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.20595\n",
      "Epoch 31/100\n",
      "919290/919290 [==============================] - 75s 82us/step - loss: 0.2052 - accuracy: 0.9281 - val_loss: 0.2061 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.20595\n",
      "Epoch 32/100\n",
      "919290/919290 [==============================] - 69s 75us/step - loss: 0.2052 - accuracy: 0.9282 - val_loss: 0.2061 - val_accuracy: 0.9284\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.20595\n",
      "Epoch 33/100\n",
      "919290/919290 [==============================] - 75s 81us/step - loss: 0.2053 - accuracy: 0.9281 - val_loss: 0.2059 - val_accuracy: 0.9284\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.20595 to 0.20592, saving model to model_4.best_v4.hdf5\n",
      "Epoch 34/100\n",
      "919290/919290 [==============================] - 69s 75us/step - loss: 0.2051 - accuracy: 0.9282 - val_loss: 0.2060 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.20592\n",
      "Epoch 35/100\n",
      "919290/919290 [==============================] - 74s 80us/step - loss: 0.2050 - accuracy: 0.9283 - val_loss: 0.2066 - val_accuracy: 0.9282\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.20592\n",
      "Epoch 36/100\n",
      "919290/919290 [==============================] - 72s 78us/step - loss: 0.2049 - accuracy: 0.9282 - val_loss: 0.2061 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.20592\n",
      "Epoch 37/100\n",
      "919290/919290 [==============================] - 72s 78us/step - loss: 0.2050 - accuracy: 0.9283 - val_loss: 0.2068 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.20592\n",
      "Epoch 38/100\n",
      "919290/919290 [==============================] - 74s 81us/step - loss: 0.2049 - accuracy: 0.9282 - val_loss: 0.2068 - val_accuracy: 0.9284\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.20592\n",
      "Epoch 39/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "919290/919290 [==============================] - 68s 74us/step - loss: 0.2048 - accuracy: 0.9283 - val_loss: 0.2067 - val_accuracy: 0.9284\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.20592\n",
      "Epoch 40/100\n",
      "919290/919290 [==============================] - 74s 80us/step - loss: 0.2048 - accuracy: 0.9282 - val_loss: 0.2059 - val_accuracy: 0.9285\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.20592\n",
      "Epoch 41/100\n",
      "919290/919290 [==============================] - 69s 75us/step - loss: 0.2047 - accuracy: 0.9282 - val_loss: 0.2063 - val_accuracy: 0.9285\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.20592\n",
      "Epoch 42/100\n",
      "919290/919290 [==============================] - 75s 81us/step - loss: 0.2046 - accuracy: 0.9281 - val_loss: 0.2066 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.20592\n",
      "Epoch 43/100\n",
      "919290/919290 [==============================] - 69s 75us/step - loss: 0.2046 - accuracy: 0.9283 - val_loss: 0.2062 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.20592\n",
      "Epoch 44/100\n",
      "919290/919290 [==============================] - 74s 80us/step - loss: 0.2045 - accuracy: 0.9283 - val_loss: 0.2062 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.20592\n",
      "Epoch 45/100\n",
      "919290/919290 [==============================] - 71s 77us/step - loss: 0.2045 - accuracy: 0.9283 - val_loss: 0.2063 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.20592\n",
      "Epoch 46/100\n",
      "919290/919290 [==============================] - 71s 78us/step - loss: 0.2044 - accuracy: 0.9283 - val_loss: 0.2064 - val_accuracy: 0.9285\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.20592\n",
      "Epoch 47/100\n",
      "919290/919290 [==============================] - 70s 76us/step - loss: 0.2043 - accuracy: 0.9285 - val_loss: 0.2063 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.20592\n",
      "Epoch 48/100\n",
      "919290/919290 [==============================] - 71s 77us/step - loss: 0.2043 - accuracy: 0.9283 - val_loss: 0.2065 - val_accuracy: 0.9285\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.20592\n",
      "Epoch 49/100\n",
      "919290/919290 [==============================] - 71s 78us/step - loss: 0.2043 - accuracy: 0.9284 - val_loss: 0.2063 - val_accuracy: 0.9287\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.20592\n",
      "Epoch 50/100\n",
      "919290/919290 [==============================] - 74s 80us/step - loss: 0.2041 - accuracy: 0.9284 - val_loss: 0.2068 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.20592\n",
      "Epoch 51/100\n",
      "919290/919290 [==============================] - 68s 74us/step - loss: 0.2041 - accuracy: 0.9284 - val_loss: 0.2064 - val_accuracy: 0.9288\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.20592\n",
      "Epoch 52/100\n",
      "919290/919290 [==============================] - 73s 79us/step - loss: 0.2041 - accuracy: 0.9284 - val_loss: 0.2063 - val_accuracy: 0.9287\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.20592\n",
      "Epoch 53/100\n",
      "919290/919290 [==============================] - 71s 78us/step - loss: 0.2041 - accuracy: 0.9285 - val_loss: 0.2065 - val_accuracy: 0.9285\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.20592\n",
      "Epoch 54/100\n",
      "919290/919290 [==============================] - 71s 77us/step - loss: 0.2040 - accuracy: 0.9284 - val_loss: 0.2063 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.20592\n",
      "Epoch 55/100\n",
      "919290/919290 [==============================] - 74s 80us/step - loss: 0.2040 - accuracy: 0.9284 - val_loss: 0.2066 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.20592\n",
      "Epoch 56/100\n",
      "919290/919290 [==============================] - 69s 75us/step - loss: 0.2039 - accuracy: 0.9284 - val_loss: 0.2064 - val_accuracy: 0.9285\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.20592\n",
      "Epoch 57/100\n",
      "919290/919290 [==============================] - 75s 81us/step - loss: 0.2038 - accuracy: 0.9284 - val_loss: 0.2065 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.20592\n",
      "Epoch 58/100\n",
      "919290/919290 [==============================] - 70s 76us/step - loss: 0.2039 - accuracy: 0.9284 - val_loss: 0.2063 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.20592\n",
      "Epoch 59/100\n",
      "919290/919290 [==============================] - 72s 78us/step - loss: 0.2038 - accuracy: 0.9284 - val_loss: 0.2066 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.20592\n",
      "Epoch 60/100\n",
      "919290/919290 [==============================] - 72s 79us/step - loss: 0.2036 - accuracy: 0.9285 - val_loss: 0.2062 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.20592\n",
      "Epoch 61/100\n",
      "919290/919290 [==============================] - 71s 77us/step - loss: 0.2036 - accuracy: 0.9286 - val_loss: 0.2065 - val_accuracy: 0.9287\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.20592\n",
      "Epoch 62/100\n",
      "919290/919290 [==============================] - 75s 81us/step - loss: 0.2037 - accuracy: 0.9286 - val_loss: 0.2068 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.20592\n",
      "Epoch 63/100\n",
      "919290/919290 [==============================] - 70s 76us/step - loss: 0.2035 - accuracy: 0.9286 - val_loss: 0.2067 - val_accuracy: 0.9287\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.20592\n",
      "Epoch 64/100\n",
      "919290/919290 [==============================] - 75s 82us/step - loss: 0.2035 - accuracy: 0.9285 - val_loss: 0.2065 - val_accuracy: 0.9288\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.20592\n",
      "Epoch 65/100\n",
      "919290/919290 [==============================] - 71s 77us/step - loss: 0.2034 - accuracy: 0.9284 - val_loss: 0.2070 - val_accuracy: 0.9284\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.20592\n",
      "Epoch 66/100\n",
      "919290/919290 [==============================] - 72s 78us/step - loss: 0.2034 - accuracy: 0.9286 - val_loss: 0.2070 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.20592\n",
      "Epoch 67/100\n",
      "919290/919290 [==============================] - 73s 80us/step - loss: 0.2034 - accuracy: 0.9286 - val_loss: 0.2067 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.20592\n",
      "Epoch 68/100\n",
      "919290/919290 [==============================] - 68s 74us/step - loss: 0.2034 - accuracy: 0.9286 - val_loss: 0.2066 - val_accuracy: 0.9285\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.20592\n",
      "Epoch 69/100\n",
      "919290/919290 [==============================] - 74s 80us/step - loss: 0.2033 - accuracy: 0.9286 - val_loss: 0.2066 - val_accuracy: 0.9287\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.20592\n",
      "Epoch 70/100\n",
      "919290/919290 [==============================] - 71s 77us/step - loss: 0.2033 - accuracy: 0.9288 - val_loss: 0.2064 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.20592\n",
      "Epoch 71/100\n",
      "919290/919290 [==============================] - 73s 80us/step - loss: 0.2033 - accuracy: 0.9285 - val_loss: 0.2069 - val_accuracy: 0.9287\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.20592\n",
      "Epoch 72/100\n",
      "919290/919290 [==============================] - 70s 76us/step - loss: 0.2032 - accuracy: 0.9286 - val_loss: 0.2064 - val_accuracy: 0.9287\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.20592\n",
      "Epoch 73/100\n",
      "919290/919290 [==============================] - 73s 79us/step - loss: 0.2030 - accuracy: 0.9287 - val_loss: 0.2067 - val_accuracy: 0.9287\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.20592\n",
      "Epoch 74/100\n",
      "919290/919290 [==============================] - 72s 78us/step - loss: 0.2030 - accuracy: 0.9287 - val_loss: 0.2070 - val_accuracy: 0.9288\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.20592\n",
      "Epoch 75/100\n",
      "919290/919290 [==============================] - 70s 76us/step - loss: 0.2029 - accuracy: 0.9286 - val_loss: 0.2080 - val_accuracy: 0.9284\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.20592\n",
      "Epoch 76/100\n",
      "919290/919290 [==============================] - 75s 82us/step - loss: 0.2029 - accuracy: 0.9286 - val_loss: 0.2071 - val_accuracy: 0.9287\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.20592\n",
      "Epoch 77/100\n",
      "919290/919290 [==============================] - 69s 75us/step - loss: 0.2029 - accuracy: 0.9287 - val_loss: 0.2071 - val_accuracy: 0.9288\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.20592\n",
      "Epoch 78/100\n",
      "919290/919290 [==============================] - 74s 81us/step - loss: 0.2029 - accuracy: 0.9287 - val_loss: 0.2067 - val_accuracy: 0.9288\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.20592\n",
      "Epoch 79/100\n",
      "919290/919290 [==============================] - 70s 76us/step - loss: 0.2028 - accuracy: 0.9287 - val_loss: 0.2068 - val_accuracy: 0.9287\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.20592\n",
      "Epoch 80/100\n",
      "919290/919290 [==============================] - 72s 78us/step - loss: 0.2027 - accuracy: 0.9288 - val_loss: 0.2068 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.20592\n",
      "Epoch 81/100\n",
      "919290/919290 [==============================] - 72s 78us/step - loss: 0.2028 - accuracy: 0.9287 - val_loss: 0.2066 - val_accuracy: 0.9289\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.20592\n",
      "Epoch 82/100\n",
      "919290/919290 [==============================] - 72s 78us/step - loss: 0.2027 - accuracy: 0.9288 - val_loss: 0.2070 - val_accuracy: 0.9288\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 0.20592\n",
      "Epoch 83/100\n",
      "919290/919290 [==============================] - 75s 81us/step - loss: 0.2027 - accuracy: 0.9287 - val_loss: 0.2067 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 0.20592\n",
      "Epoch 84/100\n",
      "919290/919290 [==============================] - 70s 76us/step - loss: 0.2027 - accuracy: 0.9288 - val_loss: 0.2065 - val_accuracy: 0.9289\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.20592\n",
      "Epoch 85/100\n",
      "919290/919290 [==============================] - 70s 76us/step - loss: 0.2024 - accuracy: 0.9288 - val_loss: 0.2071 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.20592\n",
      "Epoch 86/100\n",
      "919290/919290 [==============================] - 75s 81us/step - loss: 0.2025 - accuracy: 0.9288 - val_loss: 0.2068 - val_accuracy: 0.9287\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.20592\n",
      "Epoch 87/100\n",
      "919290/919290 [==============================] - 68s 74us/step - loss: 0.2024 - accuracy: 0.9288 - val_loss: 0.2071 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.20592\n",
      "Epoch 88/100\n",
      "919290/919290 [==============================] - 73s 79us/step - loss: 0.2024 - accuracy: 0.9287 - val_loss: 0.2069 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 0.20592\n",
      "Epoch 89/100\n",
      "919290/919290 [==============================] - 69s 75us/step - loss: 0.2023 - accuracy: 0.9288 - val_loss: 0.2074 - val_accuracy: 0.9289\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 0.20592\n",
      "Epoch 90/100\n",
      "919290/919290 [==============================] - 73s 80us/step - loss: 0.2022 - accuracy: 0.9288 - val_loss: 0.2069 - val_accuracy: 0.9289\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.20592\n",
      "Epoch 91/100\n",
      "919290/919290 [==============================] - 70s 76us/step - loss: 0.2024 - accuracy: 0.9289 - val_loss: 0.2073 - val_accuracy: 0.9288\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.20592\n",
      "Epoch 92/100\n",
      "919290/919290 [==============================] - 73s 79us/step - loss: 0.2022 - accuracy: 0.9289 - val_loss: 0.2074 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.20592\n",
      "Epoch 93/100\n",
      "919290/919290 [==============================] - 69s 75us/step - loss: 0.2022 - accuracy: 0.9288 - val_loss: 0.2072 - val_accuracy: 0.9288\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.20592\n",
      "Epoch 94/100\n",
      "919290/919290 [==============================] - 74s 80us/step - loss: 0.2021 - accuracy: 0.9288 - val_loss: 0.2070 - val_accuracy: 0.9287\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 0.20592\n",
      "Epoch 95/100\n",
      "919290/919290 [==============================] - 71s 77us/step - loss: 0.2022 - accuracy: 0.9290 - val_loss: 0.2072 - val_accuracy: 0.9289\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.20592\n",
      "Epoch 96/100\n",
      "919290/919290 [==============================] - 70s 76us/step - loss: 0.2022 - accuracy: 0.9289 - val_loss: 0.2070 - val_accuracy: 0.9288\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 0.20592\n",
      "Epoch 97/100\n",
      "919290/919290 [==============================] - 75s 82us/step - loss: 0.2020 - accuracy: 0.9289 - val_loss: 0.2075 - val_accuracy: 0.9288\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 0.20592\n",
      "Epoch 98/100\n",
      "919290/919290 [==============================] - 69s 75us/step - loss: 0.2021 - accuracy: 0.9290 - val_loss: 0.2074 - val_accuracy: 0.9287\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.20592\n",
      "Epoch 99/100\n",
      "919290/919290 [==============================] - 71s 77us/step - loss: 0.2021 - accuracy: 0.9289 - val_loss: 0.2068 - val_accuracy: 0.9288\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 0.20592\n",
      "Epoch 100/100\n",
      "919290/919290 [==============================] - 73s 80us/step - loss: 0.2021 - accuracy: 0.9289 - val_loss: 0.2078 - val_accuracy: 0.9288\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 0.20592\n",
      "1178576/1178576 [==============================] - 29s 24us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|██████████████████████████████████████████████████████████████▍               | 4/5 [8:04:50<2:01:30, 7290.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 919290 samples, validate on 229822 samples\n",
      "Epoch 1/100\n",
      "919290/919290 [==============================] - 76s 83us/step - loss: 0.2369 - accuracy: 0.9208 - val_loss: 0.2097 - val_accuracy: 0.9284\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.20966, saving model to model_5.best_v4.hdf5\n",
      "Epoch 2/100\n",
      "919290/919290 [==============================] - 69s 75us/step - loss: 0.2097 - accuracy: 0.9272 - val_loss: 0.2138 - val_accuracy: 0.9240\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.20966\n",
      "Epoch 3/100\n",
      "919290/919290 [==============================] - 75s 81us/step - loss: 0.2087 - accuracy: 0.9274 - val_loss: 0.2095 - val_accuracy: 0.9267\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.20966 to 0.20946, saving model to model_5.best_v4.hdf5\n",
      "Epoch 4/100\n",
      "919290/919290 [==============================] - 69s 76us/step - loss: 0.2082 - accuracy: 0.9275 - val_loss: 0.2122 - val_accuracy: 0.9250\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.20946\n",
      "Epoch 5/100\n",
      "919290/919290 [==============================] - 73s 80us/step - loss: 0.2078 - accuracy: 0.9274 - val_loss: 0.2074 - val_accuracy: 0.9285\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.20946 to 0.20735, saving model to model_5.best_v4.hdf5\n",
      "Epoch 6/100\n",
      "919290/919290 [==============================] - 72s 79us/step - loss: 0.2075 - accuracy: 0.9276 - val_loss: 0.2074 - val_accuracy: 0.9282\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.20735\n",
      "Epoch 7/100\n",
      "919290/919290 [==============================] - 70s 76us/step - loss: 0.2073 - accuracy: 0.9275 - val_loss: 0.2081 - val_accuracy: 0.9266\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.20735\n",
      "Epoch 8/100\n",
      "919290/919290 [==============================] - 72s 78us/step - loss: 0.2072 - accuracy: 0.9275 - val_loss: 0.2076 - val_accuracy: 0.9277\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.20735\n",
      "Epoch 9/100\n",
      "919290/919290 [==============================] - 71s 78us/step - loss: 0.2070 - accuracy: 0.9277 - val_loss: 0.2081 - val_accuracy: 0.9275\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.20735\n",
      "Epoch 10/100\n",
      "919290/919290 [==============================] - 70s 77us/step - loss: 0.2068 - accuracy: 0.9278 - val_loss: 0.2069 - val_accuracy: 0.9285\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.20735 to 0.20688, saving model to model_5.best_v4.hdf5\n",
      "Epoch 11/100\n",
      "919290/919290 [==============================] - 72s 79us/step - loss: 0.2067 - accuracy: 0.9276 - val_loss: 0.2073 - val_accuracy: 0.9276\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.20688\n",
      "Epoch 12/100\n",
      "919290/919290 [==============================] - 69s 76us/step - loss: 0.2067 - accuracy: 0.9276 - val_loss: 0.2064 - val_accuracy: 0.9287\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.20688 to 0.20638, saving model to model_5.best_v4.hdf5\n",
      "Epoch 13/100\n",
      "919290/919290 [==============================] - 76s 83us/step - loss: 0.2066 - accuracy: 0.9277 - val_loss: 0.2104 - val_accuracy: 0.9252\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.20638\n",
      "Epoch 14/100\n",
      "919290/919290 [==============================] - 69s 75us/step - loss: 0.2065 - accuracy: 0.9277 - val_loss: 0.2066 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.20638\n",
      "Epoch 15/100\n",
      "919290/919290 [==============================] - 76s 83us/step - loss: 0.2065 - accuracy: 0.9277 - val_loss: 0.2064 - val_accuracy: 0.9287\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.20638\n",
      "Epoch 16/100\n",
      "919290/919290 [==============================] - 70s 76us/step - loss: 0.2064 - accuracy: 0.9278 - val_loss: 0.2066 - val_accuracy: 0.9287\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.20638\n",
      "Epoch 17/100\n",
      "919290/919290 [==============================] - 72s 78us/step - loss: 0.2063 - accuracy: 0.9277 - val_loss: 0.2065 - val_accuracy: 0.9287\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.20638\n",
      "Epoch 18/100\n",
      "919290/919290 [==============================] - 72s 78us/step - loss: 0.2062 - accuracy: 0.9277 - val_loss: 0.2066 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.20638\n",
      "Epoch 19/100\n",
      "919290/919290 [==============================] - 75s 82us/step - loss: 0.2061 - accuracy: 0.9279 - val_loss: 0.2063 - val_accuracy: 0.9285\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.20638 to 0.20630, saving model to model_5.best_v4.hdf5\n",
      "Epoch 20/100\n",
      "919290/919290 [==============================] - 70s 77us/step - loss: 0.2060 - accuracy: 0.9279 - val_loss: 0.2065 - val_accuracy: 0.9284\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.20630\n",
      "Epoch 21/100\n",
      "919290/919290 [==============================] - 71s 78us/step - loss: 0.2060 - accuracy: 0.9280 - val_loss: 0.2068 - val_accuracy: 0.9280\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.20630\n",
      "Epoch 22/100\n",
      "919290/919290 [==============================] - 73s 80us/step - loss: 0.2058 - accuracy: 0.9279 - val_loss: 0.2068 - val_accuracy: 0.9287\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.20630\n",
      "Epoch 23/100\n",
      "919290/919290 [==============================] - 70s 76us/step - loss: 0.2059 - accuracy: 0.9279 - val_loss: 0.2070 - val_accuracy: 0.9279\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.20630\n",
      "Epoch 24/100\n",
      "919290/919290 [==============================] - 76s 83us/step - loss: 0.2057 - accuracy: 0.9280 - val_loss: 0.2066 - val_accuracy: 0.9287\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.20630\n",
      "Epoch 25/100\n",
      "919290/919290 [==============================] - 70s 76us/step - loss: 0.2057 - accuracy: 0.9279 - val_loss: 0.2066 - val_accuracy: 0.9287\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.20630\n",
      "Epoch 26/100\n",
      "919290/919290 [==============================] - 71s 77us/step - loss: 0.2055 - accuracy: 0.9281 - val_loss: 0.2069 - val_accuracy: 0.9280\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.20630\n",
      "Epoch 27/100\n",
      "919290/919290 [==============================] - 75s 82us/step - loss: 0.2056 - accuracy: 0.9281 - val_loss: 0.2065 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.20630\n",
      "Epoch 28/100\n",
      "919290/919290 [==============================] - 70s 76us/step - loss: 0.2054 - accuracy: 0.9280 - val_loss: 0.2065 - val_accuracy: 0.9287\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.20630\n",
      "Epoch 29/100\n",
      "919290/919290 [==============================] - 74s 80us/step - loss: 0.2054 - accuracy: 0.9281 - val_loss: 0.2069 - val_accuracy: 0.9283\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.20630\n",
      "Epoch 30/100\n",
      "919290/919290 [==============================] - 73s 79us/step - loss: 0.2053 - accuracy: 0.9281 - val_loss: 0.2065 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.20630\n",
      "Epoch 31/100\n",
      "919290/919290 [==============================] - 74s 81us/step - loss: 0.2054 - accuracy: 0.9281 - val_loss: 0.2069 - val_accuracy: 0.9287\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.20630\n",
      "Epoch 32/100\n",
      "919290/919290 [==============================] - 70s 76us/step - loss: 0.2052 - accuracy: 0.9280 - val_loss: 0.2064 - val_accuracy: 0.9285\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.20630\n",
      "Epoch 33/100\n",
      "919290/919290 [==============================] - 74s 80us/step - loss: 0.2052 - accuracy: 0.9280 - val_loss: 0.2065 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.20630\n",
      "Epoch 34/100\n",
      "919290/919290 [==============================] - 73s 80us/step - loss: 0.2051 - accuracy: 0.9281 - val_loss: 0.2065 - val_accuracy: 0.9285\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.20630\n",
      "Epoch 35/100\n",
      "919290/919290 [==============================] - 70s 76us/step - loss: 0.2051 - accuracy: 0.9283 - val_loss: 0.2065 - val_accuracy: 0.9288\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.20630\n",
      "Epoch 36/100\n",
      "919290/919290 [==============================] - 75s 82us/step - loss: 0.2049 - accuracy: 0.9281 - val_loss: 0.2069 - val_accuracy: 0.9287\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.20630\n",
      "Epoch 37/100\n",
      "919290/919290 [==============================] - 73s 80us/step - loss: 0.2049 - accuracy: 0.9282 - val_loss: 0.2066 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.20630\n",
      "Epoch 38/100\n",
      "919290/919290 [==============================] - 69s 75us/step - loss: 0.2049 - accuracy: 0.9283 - val_loss: 0.2065 - val_accuracy: 0.9288\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.20630\n",
      "Epoch 39/100\n",
      "919290/919290 [==============================] - 74s 80us/step - loss: 0.2049 - accuracy: 0.9283 - val_loss: 0.2065 - val_accuracy: 0.9287\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00039: val_loss did not improve from 0.20630\n",
      "Epoch 40/100\n",
      "919290/919290 [==============================] - 69s 75us/step - loss: 0.2048 - accuracy: 0.9281 - val_loss: 0.2066 - val_accuracy: 0.9288\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.20630\n",
      "Epoch 41/100\n",
      "919290/919290 [==============================] - 72s 79us/step - loss: 0.2048 - accuracy: 0.9283 - val_loss: 0.2067 - val_accuracy: 0.9285\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.20630\n",
      "Epoch 42/100\n",
      "919290/919290 [==============================] - 73s 80us/step - loss: 0.2047 - accuracy: 0.9283 - val_loss: 0.2064 - val_accuracy: 0.9287\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.20630\n",
      "Epoch 43/100\n",
      "919290/919290 [==============================] - 70s 76us/step - loss: 0.2046 - accuracy: 0.9283 - val_loss: 0.2069 - val_accuracy: 0.9287\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.20630\n",
      "Epoch 44/100\n",
      "919290/919290 [==============================] - 76s 83us/step - loss: 0.2047 - accuracy: 0.9283 - val_loss: 0.2066 - val_accuracy: 0.9289\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.20630\n",
      "Epoch 45/100\n",
      "919290/919290 [==============================] - 69s 75us/step - loss: 0.2045 - accuracy: 0.9282 - val_loss: 0.2066 - val_accuracy: 0.9288\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.20630\n",
      "Epoch 46/100\n",
      "919290/919290 [==============================] - 75s 81us/step - loss: 0.2044 - accuracy: 0.9284 - val_loss: 0.2070 - val_accuracy: 0.9283\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.20630\n",
      "Epoch 47/100\n",
      "919290/919290 [==============================] - 71s 77us/step - loss: 0.2045 - accuracy: 0.9283 - val_loss: 0.2065 - val_accuracy: 0.9287\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.20630\n",
      "Epoch 48/100\n",
      "919290/919290 [==============================] - 73s 79us/step - loss: 0.2043 - accuracy: 0.9283 - val_loss: 0.2068 - val_accuracy: 0.9288\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.20630\n",
      "Epoch 49/100\n",
      "919290/919290 [==============================] - 72s 79us/step - loss: 0.2043 - accuracy: 0.9283 - val_loss: 0.2068 - val_accuracy: 0.9285\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.20630\n",
      "Epoch 50/100\n",
      "919290/919290 [==============================] - 72s 78us/step - loss: 0.2043 - accuracy: 0.9284 - val_loss: 0.2067 - val_accuracy: 0.9287\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.20630\n",
      "Epoch 51/100\n",
      "919290/919290 [==============================] - 74s 81us/step - loss: 0.2042 - accuracy: 0.9285 - val_loss: 0.2066 - val_accuracy: 0.9285\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.20630\n",
      "Epoch 52/100\n",
      "919290/919290 [==============================] - 71s 77us/step - loss: 0.2041 - accuracy: 0.9283 - val_loss: 0.2066 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.20630\n",
      "Epoch 53/100\n",
      "919290/919290 [==============================] - 72s 78us/step - loss: 0.2042 - accuracy: 0.9283 - val_loss: 0.2067 - val_accuracy: 0.9289\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.20630\n",
      "Epoch 54/100\n",
      "919290/919290 [==============================] - 76s 82us/step - loss: 0.2041 - accuracy: 0.9284 - val_loss: 0.2067 - val_accuracy: 0.9287\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.20630\n",
      "Epoch 55/100\n",
      "919290/919290 [==============================] - 69s 75us/step - loss: 0.2040 - accuracy: 0.9285 - val_loss: 0.2066 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.20630\n",
      "Epoch 56/100\n",
      "919290/919290 [==============================] - 75s 81us/step - loss: 0.2039 - accuracy: 0.9285 - val_loss: 0.2067 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.20630\n",
      "Epoch 57/100\n",
      "919290/919290 [==============================] - 70s 76us/step - loss: 0.2039 - accuracy: 0.9285 - val_loss: 0.2067 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.20630\n",
      "Epoch 58/100\n",
      "919290/919290 [==============================] - 74s 80us/step - loss: 0.2037 - accuracy: 0.9284 - val_loss: 0.2067 - val_accuracy: 0.9285\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.20630\n",
      "Epoch 59/100\n",
      "919290/919290 [==============================] - 72s 78us/step - loss: 0.2037 - accuracy: 0.9286 - val_loss: 0.2067 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.20630\n",
      "Epoch 60/100\n",
      "919290/919290 [==============================] - 70s 76us/step - loss: 0.2038 - accuracy: 0.9284 - val_loss: 0.2066 - val_accuracy: 0.9288\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.20630\n",
      "Epoch 61/100\n",
      "919290/919290 [==============================] - 76s 83us/step - loss: 0.2037 - accuracy: 0.9285 - val_loss: 0.2067 - val_accuracy: 0.9288\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.20630\n",
      "Epoch 62/100\n",
      "919290/919290 [==============================] - 69s 75us/step - loss: 0.2036 - accuracy: 0.9284 - val_loss: 0.2069 - val_accuracy: 0.9288\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.20630\n",
      "Epoch 63/100\n",
      "919290/919290 [==============================] - 75s 81us/step - loss: 0.2036 - accuracy: 0.9286 - val_loss: 0.2067 - val_accuracy: 0.9288\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.20630\n",
      "Epoch 64/100\n",
      "919290/919290 [==============================] - 73s 80us/step - loss: 0.2036 - accuracy: 0.9284 - val_loss: 0.2067 - val_accuracy: 0.9288\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.20630\n",
      "Epoch 65/100\n",
      "919290/919290 [==============================] - 70s 76us/step - loss: 0.2035 - accuracy: 0.9286 - val_loss: 0.2069 - val_accuracy: 0.9287\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.20630\n",
      "Epoch 66/100\n",
      "919290/919290 [==============================] - 74s 81us/step - loss: 0.2033 - accuracy: 0.9286 - val_loss: 0.2068 - val_accuracy: 0.9288\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.20630\n",
      "Epoch 67/100\n",
      "919290/919290 [==============================] - 72s 79us/step - loss: 0.2035 - accuracy: 0.9286 - val_loss: 0.2081 - val_accuracy: 0.9287\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.20630\n",
      "Epoch 68/100\n",
      "919290/919290 [==============================] - 75s 81us/step - loss: 0.2034 - accuracy: 0.9286 - val_loss: 0.2069 - val_accuracy: 0.9285\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.20630\n",
      "Epoch 69/100\n",
      "919290/919290 [==============================] - 72s 78us/step - loss: 0.2034 - accuracy: 0.9285 - val_loss: 0.2069 - val_accuracy: 0.9289\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.20630\n",
      "Epoch 70/100\n",
      "919290/919290 [==============================] - 72s 78us/step - loss: 0.2034 - accuracy: 0.9286 - val_loss: 0.2073 - val_accuracy: 0.9285\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.20630\n",
      "Epoch 71/100\n",
      "919290/919290 [==============================] - 73s 80us/step - loss: 0.2032 - accuracy: 0.9286 - val_loss: 0.2069 - val_accuracy: 0.9287\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.20630\n",
      "Epoch 72/100\n",
      "919290/919290 [==============================] - 73s 80us/step - loss: 0.2031 - accuracy: 0.9287 - val_loss: 0.2069 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.20630\n",
      "Epoch 73/100\n",
      "919290/919290 [==============================] - 71s 77us/step - loss: 0.2032 - accuracy: 0.9286 - val_loss: 0.2068 - val_accuracy: 0.9288\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.20630\n",
      "Epoch 74/100\n",
      "919290/919290 [==============================] - 75s 81us/step - loss: 0.2031 - accuracy: 0.9287 - val_loss: 0.2069 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.20630\n",
      "Epoch 75/100\n",
      "919290/919290 [==============================] - 71s 78us/step - loss: 0.2029 - accuracy: 0.9288 - val_loss: 0.2071 - val_accuracy: 0.9283\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.20630\n",
      "Epoch 76/100\n",
      "919290/919290 [==============================] - 73s 79us/step - loss: 0.2031 - accuracy: 0.9287 - val_loss: 0.2075 - val_accuracy: 0.9288\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.20630\n",
      "Epoch 77/100\n",
      "919290/919290 [==============================] - 70s 77us/step - loss: 0.2029 - accuracy: 0.9288 - val_loss: 0.2070 - val_accuracy: 0.9285\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.20630\n",
      "Epoch 78/100\n",
      "919290/919290 [==============================] - 75s 82us/step - loss: 0.2029 - accuracy: 0.9286 - val_loss: 0.2071 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.20630\n",
      "Epoch 79/100\n",
      "919290/919290 [==============================] - 70s 77us/step - loss: 0.2027 - accuracy: 0.9288 - val_loss: 0.2070 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.20630\n",
      "Epoch 80/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "919290/919290 [==============================] - 73s 80us/step - loss: 0.2029 - accuracy: 0.9287 - val_loss: 0.2070 - val_accuracy: 0.9285\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.20630\n",
      "Epoch 81/100\n",
      "919290/919290 [==============================] - 75s 82us/step - loss: 0.2027 - accuracy: 0.9288 - val_loss: 0.2074 - val_accuracy: 0.9288\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.20630\n",
      "Epoch 82/100\n",
      "919290/919290 [==============================] - 70s 76us/step - loss: 0.2026 - accuracy: 0.9287 - val_loss: 0.2073 - val_accuracy: 0.9288\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 0.20630\n",
      "Epoch 83/100\n",
      "919290/919290 [==============================] - 72s 79us/step - loss: 0.2028 - accuracy: 0.9287 - val_loss: 0.2074 - val_accuracy: 0.9284\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 0.20630\n",
      "Epoch 84/100\n",
      "919290/919290 [==============================] - 70s 76us/step - loss: 0.2025 - accuracy: 0.9288 - val_loss: 0.2074 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.20630\n",
      "Epoch 85/100\n",
      "919290/919290 [==============================] - 74s 80us/step - loss: 0.2026 - accuracy: 0.9288 - val_loss: 0.2072 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.20630\n",
      "Epoch 86/100\n",
      "919290/919290 [==============================] - 73s 79us/step - loss: 0.2026 - accuracy: 0.9288 - val_loss: 0.2076 - val_accuracy: 0.9287\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.20630\n",
      "Epoch 87/100\n",
      "919290/919290 [==============================] - 72s 78us/step - loss: 0.2025 - accuracy: 0.9289 - val_loss: 0.2070 - val_accuracy: 0.9284\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.20630\n",
      "Epoch 88/100\n",
      "919290/919290 [==============================] - 70s 76us/step - loss: 0.2025 - accuracy: 0.9289 - val_loss: 0.2071 - val_accuracy: 0.9283\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 0.20630\n",
      "Epoch 89/100\n",
      "919290/919290 [==============================] - 74s 80us/step - loss: 0.2025 - accuracy: 0.9287 - val_loss: 0.2072 - val_accuracy: 0.9287\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 0.20630\n",
      "Epoch 90/100\n",
      "919290/919290 [==============================] - 70s 77us/step - loss: 0.2025 - accuracy: 0.9288 - val_loss: 0.2076 - val_accuracy: 0.9287\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.20630\n",
      "Epoch 91/100\n",
      "919290/919290 [==============================] - 75s 81us/step - loss: 0.2023 - accuracy: 0.9288 - val_loss: 0.2074 - val_accuracy: 0.9288\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.20630\n",
      "Epoch 92/100\n",
      "919290/919290 [==============================] - 70s 77us/step - loss: 0.2024 - accuracy: 0.9289 - val_loss: 0.2073 - val_accuracy: 0.9288\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.20630\n",
      "Epoch 93/100\n",
      "919290/919290 [==============================] - 76s 82us/step - loss: 0.2022 - accuracy: 0.9289 - val_loss: 0.2077 - val_accuracy: 0.9288\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.20630\n",
      "Epoch 94/100\n",
      "919290/919290 [==============================] - 71s 77us/step - loss: 0.2022 - accuracy: 0.9289 - val_loss: 0.2073 - val_accuracy: 0.9285\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 0.20630\n",
      "Epoch 95/100\n",
      "919290/919290 [==============================] - 73s 79us/step - loss: 0.2022 - accuracy: 0.9290 - val_loss: 0.2075 - val_accuracy: 0.9282\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.20630\n",
      "Epoch 96/100\n",
      "919290/919290 [==============================] - 73s 79us/step - loss: 0.2023 - accuracy: 0.9289 - val_loss: 0.2071 - val_accuracy: 0.9287\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 0.20630\n",
      "Epoch 97/100\n",
      "919290/919290 [==============================] - 69s 75us/step - loss: 0.2022 - accuracy: 0.9287 - val_loss: 0.2073 - val_accuracy: 0.9285\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 0.20630\n",
      "Epoch 98/100\n",
      "919290/919290 [==============================] - 76s 83us/step - loss: 0.2021 - accuracy: 0.9289 - val_loss: 0.2080 - val_accuracy: 0.9285\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.20630\n",
      "Epoch 99/100\n",
      "919290/919290 [==============================] - 70s 76us/step - loss: 0.2021 - accuracy: 0.9289 - val_loss: 0.2070 - val_accuracy: 0.9289\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 0.20630\n",
      "Epoch 100/100\n",
      "919290/919290 [==============================] - 74s 81us/step - loss: 0.2020 - accuracy: 0.9288 - val_loss: 0.2074 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 0.20630\n",
      "1178576/1178576 [==============================] - 32s 27us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 5/5 [10:06:00<00:00, 7272.13s/it]\n"
     ]
    }
   ],
   "source": [
    "y_pred_all=[]\n",
    "for i in tqdm(range(1,6)):\n",
    "    ## load data \n",
    "    X_train=joblib.load('X_train_modify_{}_v4.pkl'.format(i))\n",
    "    Y_train=joblib.load('Y_train_modify_{}_v4.pkl'.format(i))\n",
    "    X_valid=joblib.load('X_valid_modify_{}_v4.pkl'.format(i))\n",
    "    Y_valid=joblib.load('Y_valid_modify_{}_v4.pkl'.format(i))\n",
    "    ## scale data\n",
    "    scaler=MinMaxScaler()\n",
    "    X_scaled_train=scaler.fit_transform(X_train)\n",
    "    X_scaled_valid=scaler.transform(X_valid)\n",
    "    X_scaled_test=scaler.transform(X_test.values)\n",
    "    ## train data\n",
    "    NNmodel(X_scaled_train, Y_train,X_scaled_valid, Y_valid,'adamax',1000,100, \\\n",
    "            500, 400, 400,200, 150,150,0.4, 0.4, 'normal',i)\n",
    "    ## predict data\n",
    "    y_pred_test=NNmodel_prediction(X_scaled_test,'adamax', 1000,500, 400, 400,200, 150,150, 0.4, 0.4, 'normal',i)\n",
    "    y_pred_all.append(y_pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred_all here is state of 22nd order for user 15 and probability of purchaing \n",
    "\n",
    "y_pred_all=np.array(y_pred_all)\n",
    "y_pred_average=np.average(y_pred_all, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1178576"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_pred_average)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('y_pred_average_v4.npy', y_pred_average)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.18260631],\n",
       "       [0.18450725],\n",
       "       [0.05097334],\n",
       "       ...,\n",
       "       [0.00205428],\n",
       "       [0.00280767],\n",
       "       [0.00295321]], dtype=float32)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_average = np.load(\"y_pred_average_v4.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1178576, 45)\n",
      "(1178576, 46)\n"
     ]
    }
   ],
   "source": [
    "# Append prob back to original x_test\n",
    "X_test=pd.read_csv('X_test_v4.csv')\n",
    "print(X_test.shape)\n",
    "X_test[\"prediction_prob\"] = y_pred_average\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# two level of validation \n",
    "# 1st : is for binary classification prediction compare between train from train_set (X) and validation from train_set(X) \n",
    "# 2nd : is for prediction compare with Dream model for the best 10 selected \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test[\"prob_rank\"] = X_test.groupby(\"user_id\")[\"prediction_prob\"].rank(ascending=False)\n",
    "rank_df =  X_test[[\"user_id\",\"product_id\",\"prediction_prob\",\"prob_rank\"]]\n",
    "rank_df = rank_df[rank_df.prob_rank <= 15]\n",
    "rank_df.sort_values([\"user_id\",\"prob_rank\"])\n",
    "df_pred = copy.deepcopy(rank_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>prediction_prob</th>\n",
       "      <th>prob_rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11</td>\n",
       "      <td>4238.0</td>\n",
       "      <td>0.182606</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11</td>\n",
       "      <td>4310.0</td>\n",
       "      <td>0.184507</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>11</td>\n",
       "      <td>7118.0</td>\n",
       "      <td>0.121767</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>11</td>\n",
       "      <td>14531.0</td>\n",
       "      <td>0.179067</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>11</td>\n",
       "      <td>20035.0</td>\n",
       "      <td>0.059272</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>11</td>\n",
       "      <td>20213.0</td>\n",
       "      <td>0.424928</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>11</td>\n",
       "      <td>20460.0</td>\n",
       "      <td>0.268277</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>11</td>\n",
       "      <td>33482.0</td>\n",
       "      <td>0.069576</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>11</td>\n",
       "      <td>33947.0</td>\n",
       "      <td>0.356440</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>11</td>\n",
       "      <td>33982.0</td>\n",
       "      <td>0.206245</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>11</td>\n",
       "      <td>34211.0</td>\n",
       "      <td>0.063879</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>11</td>\n",
       "      <td>43294.0</td>\n",
       "      <td>0.088556</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>11</td>\n",
       "      <td>53994.0</td>\n",
       "      <td>0.114840</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>11</td>\n",
       "      <td>55118.0</td>\n",
       "      <td>0.105632</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>11</td>\n",
       "      <td>56329.0</td>\n",
       "      <td>0.298721</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    user_id  product_id  prediction_prob  prob_rank\n",
       "0        11      4238.0         0.182606        7.0\n",
       "1        11      4310.0         0.184507        6.0\n",
       "6        11      7118.0         0.121767        9.0\n",
       "15       11     14531.0         0.179067        8.0\n",
       "18       11     20035.0         0.059272       15.0\n",
       "19       11     20213.0         0.424928        1.0\n",
       "20       11     20460.0         0.268277        4.0\n",
       "26       11     33482.0         0.069576       13.0\n",
       "28       11     33947.0         0.356440        2.0\n",
       "29       11     33982.0         0.206245        5.0\n",
       "30       11     34211.0         0.063879       14.0\n",
       "38       11     43294.0         0.088556       12.0\n",
       "41       11     53994.0         0.114840       10.0\n",
       "44       11     55118.0         0.105632       11.0\n",
       "45       11     56329.0         0.298721        3.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pred[df_pred.user_id == 11]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare with last order in prior_train (actual data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>user_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>order_number</th>\n",
       "      <th>total_orders_user</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2787881</td>\n",
       "      <td>11</td>\n",
       "      <td>21036.0</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2787882</td>\n",
       "      <td>11</td>\n",
       "      <td>42094.0</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2787883</td>\n",
       "      <td>11</td>\n",
       "      <td>5038.0</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2787884</td>\n",
       "      <td>11</td>\n",
       "      <td>20680.0</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2787885</td>\n",
       "      <td>11</td>\n",
       "      <td>54031.0</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193798</th>\n",
       "      <td>3199351</td>\n",
       "      <td>206202</td>\n",
       "      <td>33302.0</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193799</th>\n",
       "      <td>3199352</td>\n",
       "      <td>206202</td>\n",
       "      <td>32906.0</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193800</th>\n",
       "      <td>3213988</td>\n",
       "      <td>206206</td>\n",
       "      <td>13044.0</td>\n",
       "      <td>67</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193801</th>\n",
       "      <td>3213989</td>\n",
       "      <td>206206</td>\n",
       "      <td>24870.0</td>\n",
       "      <td>67</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193802</th>\n",
       "      <td>3213990</td>\n",
       "      <td>206206</td>\n",
       "      <td>7485.0</td>\n",
       "      <td>67</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>193803 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          index  user_id  product_id  order_number  total_orders_user\n",
       "0       2787881       11     21036.0             7                  7\n",
       "1       2787882       11     42094.0             7                  7\n",
       "2       2787883       11      5038.0             7                  7\n",
       "3       2787884       11     20680.0             7                  7\n",
       "4       2787885       11     54031.0             7                  7\n",
       "...         ...      ...         ...           ...                ...\n",
       "193798  3199351   206202     33302.0            22                 22\n",
       "193799  3199352   206202     32906.0            22                 22\n",
       "193800  3213988   206206     13044.0            67                 67\n",
       "193801  3213989   206206     24870.0            67                 67\n",
       "193802  3213990   206206      7485.0            67                 67\n",
       "\n",
       "[193803 rows x 5 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prior_train = pd.read_csv('prior_train_james_v3.csv') # prior_train_final v3 is okay\n",
    "prior_train = prior_train[prior_train.eval_set != \"test\"]\n",
    "user_maxorder_map = prior_train.groupby(\"user_id\").agg({\"order_number\":\"max\"}).reset_index()\n",
    "user_maxorder_map.rename(columns = {\"order_number\":\"total_orders_user\"}, inplace = True)\n",
    "entire_df = pd.merge(prior_train,user_maxorder_map, on =\"user_id\", how = \"left\").sort_values([\"user_id\",\"order_number\"])\n",
    "df_act = entire_df[entire_df.order_number == entire_df.total_orders_user ][[\"user_id\",\"product_id\",\"order_number\",\"total_orders_user\"]].reset_index()\n",
    "df_act #actual last order (i.e 22nd order for user 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>prediction_prob</th>\n",
       "      <th>prob_rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>11</td>\n",
       "      <td>20213.0</td>\n",
       "      <td>0.424928</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>11</td>\n",
       "      <td>33947.0</td>\n",
       "      <td>0.356440</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>11</td>\n",
       "      <td>56329.0</td>\n",
       "      <td>0.298721</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>11</td>\n",
       "      <td>20460.0</td>\n",
       "      <td>0.268277</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>11</td>\n",
       "      <td>33982.0</td>\n",
       "      <td>0.206245</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11</td>\n",
       "      <td>4310.0</td>\n",
       "      <td>0.184507</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11</td>\n",
       "      <td>4238.0</td>\n",
       "      <td>0.182606</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>11</td>\n",
       "      <td>14531.0</td>\n",
       "      <td>0.179067</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>11</td>\n",
       "      <td>7118.0</td>\n",
       "      <td>0.121767</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>11</td>\n",
       "      <td>53994.0</td>\n",
       "      <td>0.114840</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>11</td>\n",
       "      <td>55118.0</td>\n",
       "      <td>0.105632</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>11</td>\n",
       "      <td>43294.0</td>\n",
       "      <td>0.088556</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>11</td>\n",
       "      <td>33482.0</td>\n",
       "      <td>0.069576</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>11</td>\n",
       "      <td>34211.0</td>\n",
       "      <td>0.063879</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>11</td>\n",
       "      <td>20035.0</td>\n",
       "      <td>0.059272</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    user_id  product_id  prediction_prob  prob_rank\n",
       "19       11     20213.0         0.424928        1.0\n",
       "28       11     33947.0         0.356440        2.0\n",
       "45       11     56329.0         0.298721        3.0\n",
       "20       11     20460.0         0.268277        4.0\n",
       "29       11     33982.0         0.206245        5.0\n",
       "1        11      4310.0         0.184507        6.0\n",
       "0        11      4238.0         0.182606        7.0\n",
       "15       11     14531.0         0.179067        8.0\n",
       "6        11      7118.0         0.121767        9.0\n",
       "41       11     53994.0         0.114840       10.0\n",
       "44       11     55118.0         0.105632       11.0\n",
       "38       11     43294.0         0.088556       12.0\n",
       "26       11     33482.0         0.069576       13.0\n",
       "30       11     34211.0         0.063879       14.0\n",
       "18       11     20035.0         0.059272       15.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pred[df_pred.user_id == 11].sort_values(\"prob_rank\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation matrix \n",
    "def cal_confidence_score(user_id, df_act,df_pred):\n",
    "    \n",
    "    actual_basket_food_list = df_act[df_act.user_id == user_id].product_id.tolist()\n",
    "    pred_top_10_food_list    = df_pred[df_pred.user_id == user_id].product_id.tolist()\n",
    "    \n",
    "    if len(actual_basket_food_list) < 15:\n",
    "        # evaluate whether top 10 items predicted are in actual basket \n",
    "        confi_score = len([i for i in pred_top_10_food_list if i in actual_basket_food_list])/len(actual_basket_food_list)\n",
    "    else:\n",
    "        confi_score = len([i for i in pred_top_10_food_list if i in actual_basket_food_list])/15\n",
    "\n",
    "    return(confi_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21036.0, 42094.0, 5038.0, 20680.0, 54031.0, 40984.0, 34211.0, 53470.0, 10488.0, 56329.0, 33982.0]\n",
      "[4238.0, 4310.0, 7118.0, 14531.0, 20035.0, 20213.0, 20460.0, 33482.0, 33947.0, 33982.0, 34211.0, 43294.0, 53994.0, 55118.0, 56329.0]\n"
     ]
    }
   ],
   "source": [
    "cal_confidence_score(11, df_act,df_pred)\n",
    "actual_basket_food_list = df_act[df_act.user_id == 11].product_id.tolist()\n",
    "pred_top_10_food_list   = df_pred[df_pred.user_id == 11].product_id.tolist()\n",
    "print(actual_basket_food_list)\n",
    "print(pred_top_10_food_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2727272727272727"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cal_confidence_score(11,df_act,df_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_confi_score = df_act.drop_duplicates(subset= [\"user_id\"], keep = \"first\")[\"user_id\"].reset_index()\n",
    "user_confi_score[\"confi_score\"] = user_confi_score.user_id.apply(lambda x: cal_confidence_score(x, df_act,df_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins   = [0,0.2,0.4,0.6,0.8,1.0]\n",
    "labels = [\"0-0.2\",\"0.2-0.4\",\"0.4-0.6\",\"0.6-0.8\",\"0.8-1.0\"]\n",
    "user_confi_score['confi_bucket'] = pd.cut(user_confi_score[\"confi_score\"], bins=bins, labels=labels, include_lowest=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>confi_bucket</th>\n",
       "      <th>frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.2-0.4</td>\n",
       "      <td>5039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.4-0.6</td>\n",
       "      <td>4941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0-0.2</td>\n",
       "      <td>4082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.8-1.0</td>\n",
       "      <td>3246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.6-0.8</td>\n",
       "      <td>3079</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  confi_bucket  frequency\n",
       "0      0.2-0.4       5039\n",
       "1      0.4-0.6       4941\n",
       "2        0-0.2       4082\n",
       "3      0.8-1.0       3246\n",
       "4      0.6-0.8       3079"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confi_score_result = pd.DataFrame(user_confi_score.confi_bucket.value_counts()).reset_index()\n",
    "confi_score_result.rename(columns = {\"index\":\"confi_bucket\",\"confi_bucket\":\"frequency\"},inplace = True)\n",
    "confi_score_result.sort_values(\"frequency\",ascending = False) #average size of the basket # how many "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "confi_score_result[\"percent\"] = round(confi_score_result.frequency/sum(confi_score_result.frequency),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>confi_bucket</th>\n",
       "      <th>frequency</th>\n",
       "      <th>percent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.2-0.4</td>\n",
       "      <td>5039</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.4-0.6</td>\n",
       "      <td>4941</td>\n",
       "      <td>0.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0-0.2</td>\n",
       "      <td>4082</td>\n",
       "      <td>0.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.8-1.0</td>\n",
       "      <td>3246</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.6-0.8</td>\n",
       "      <td>3079</td>\n",
       "      <td>0.15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  confi_bucket  frequency  percent\n",
       "0      0.2-0.4       5039     0.25\n",
       "1      0.4-0.6       4941     0.24\n",
       "2        0-0.2       4082     0.20\n",
       "3      0.8-1.0       3246     0.16\n",
       "4      0.6-0.8       3079     0.15"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confi_score_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>confi_bucket</th>\n",
       "      <th>frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0-0.2</td>\n",
       "      <td>6495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.2-0.4</td>\n",
       "      <td>5654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.4-0.6</td>\n",
       "      <td>3956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.8-1.0</td>\n",
       "      <td>2289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.6-0.8</td>\n",
       "      <td>1994</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  confi_bucket  frequency\n",
       "0        0-0.2       6495\n",
       "1      0.2-0.4       5654\n",
       "2      0.4-0.6       3956\n",
       "3      0.8-1.0       2289\n",
       "4      0.6-0.8       1994"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# v3 result without nutrition\n",
    "\n",
    "confi_score_result = pd.DataFrame(user_confi_score.confi_bucket.value_counts()).reset_index()\n",
    "confi_score_result.rename(columns = {\"index\":\"confi_bucket\",\"confi_bucket\":\"frequency\"},inplace = True)\n",
    "confi_score_result.sort_values(\"frequency\",ascending = False) #average size of the basket # how many "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>user_id</th>\n",
       "      <th>confi_score</th>\n",
       "      <th>confi_bucket</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.2-0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0-0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20</td>\n",
       "      <td>14</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.4-0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>32</td>\n",
       "      <td>23</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.4-0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>42</td>\n",
       "      <td>34</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.8-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20383</th>\n",
       "      <td>193768</td>\n",
       "      <td>206168</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.6-0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20384</th>\n",
       "      <td>193773</td>\n",
       "      <td>206177</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.2-0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20385</th>\n",
       "      <td>193777</td>\n",
       "      <td>206182</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.2-0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20386</th>\n",
       "      <td>193790</td>\n",
       "      <td>206202</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.6-0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20387</th>\n",
       "      <td>193800</td>\n",
       "      <td>206206</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.6-0.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20388 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        index  user_id  confi_score confi_bucket\n",
       "0           0       11     0.272727      0.2-0.4\n",
       "1          11       12     0.000000        0-0.2\n",
       "2          20       14     0.416667      0.4-0.6\n",
       "3          32       23     0.500000      0.4-0.6\n",
       "4          42       34     1.000000      0.8-1.0\n",
       "...       ...      ...          ...          ...\n",
       "20383  193768   206168     0.800000      0.6-0.8\n",
       "20384  193773   206177     0.250000      0.2-0.4\n",
       "20385  193777   206182     0.307692      0.2-0.4\n",
       "20386  193790   206202     0.700000      0.6-0.8\n",
       "20387  193800   206206     0.666667      0.6-0.8\n",
       "\n",
       "[20388 rows x 4 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_confi_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_user = pd.read_csv(\"C:/Users/wanyi/Desktop/Research Design/Clustering/20kusers_new.csv\",usecols = [\"user_id\",\"kmean_cust_type\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merg = pd.merge(user_confi_score,sampled_user, on=\"user_id\", how = \"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "user20k_confscore_label = df_merg[[\"user_id\",\"confi_score\",\"confi_bucket\",\"kmean_cust_type\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "user20k_confscore_label.to_csv(\"user20k_confscore_label.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kaggle results "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align:justify\"><span style=\"color:black; font-family:Times New Roman; font-size:1.5em;line-height:1.4em;\">\n",
    "In the Kaggle competition of Instacart Market Basket Analysis, the evaluation of the prediction results is based on the F1 score. The F1 score is a weighted average of precision and recall. The F1 score needs be maximized to ensure that both precision and recall are high. In order to maximize the F1 score, an appropriate probability threshold is set to predict the output labels of the test data. In the end, the prediction of the reordered products in the latest purchase of the test users is summited to Kaggle. The F1 score shown in the Leaderboard of Kaggle is 0.373. \n",
    " </span></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresh=0.24\n",
    "y_pred_binary=np.where(y_pred_average[:, 0]>thresh, 1,0)\n",
    "X_test_new=X_test.copy()\n",
    "X_test_new['pred']=y_pred_binary\n",
    "X_test_new['prediction_pro']=y_pred_test[:, 0]\n",
    "X_test_new['product_id']=X_test_new['product_id'].astype(int)\n",
    "prediction=X_test_new[X_test_new.pred==1].groupby('user_id')['product_id'].\\\n",
    "apply(lambda x: ' '.join([str(e) for e in set(x)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv(\"sample_submission.csv\")\n",
    "prior_train=pd.read_csv('prior_train_final.csv')\n",
    "submission=pd.merge(test, prior_train,on='order_id', how='left')[['order_id', 'user_id']]\n",
    "submission['products']=submission.user_id.map(prediction)\n",
    "submission['products'].fillna('None', inplace=True)\n",
    "submission[['order_id','products']].to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align:center\"><span style=\"color:blue; font-family:Times New Roman; font-size:3em;\"> Conclusion  </span></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align:justify\"><span style=\"color:black; font-family:Times New Roman; font-size:1.5em;line-height:1.4em;\"> \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "In this project, I have developed a neural network model to predict which products users will buy again in their next purchase. The NN model combined with feature engineering technique can well capture both sequential behavior and general taste of users, leading to 0.373 of the F1 score in the Kaggle competition of Instacart Market Basket Analysis. If a model ensembling technique (a neural network model + XGBoost ) is used, it can push the F1 score in the leaderboard to 0.383 and achieve the ranking of top 9% in this competition. \n",
    " </span></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X       =pd.read_csv('X.csv')\n",
    "X_test  =pd.read_csv('X_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=X.take(np.random.permutation(len(X))) #shuffle rows in the X. as such no longer on a user level\n",
    "Y=X['reordered']\n",
    "X.drop(['reordered','user_id', 'product_id','Unnamed: 0'], axis=1, inplace=True)\n",
    "X_test.drop(['user_id', 'product_id','Unnamed: 0'], axis=1, inplace=True)\n",
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "skf_new = StratifiedKFold(n_splits=5)\n",
    "i=1\n",
    "for train_index_new, valid_index_new  in skf_new.split(X, Y): #X, Y here are train..so for user 15 upto order # 21\n",
    "    joblib.dump(X.values[train_index_new],'X_train_new_modify_{}_ahhahaha.pkl'.format(i))\n",
    "    joblib.dump(Y.values[train_index_new],'Y_train_new_modify_{}_ahhahaha.pkl'.format(i))\n",
    "    joblib.dump(X.values[valid_index_new],'X_valid_new_modify_{}_ahhahaha.pkl'.format(i))\n",
    "    joblib.dump(Y.values[valid_index_new],'Y_valid_new_modify_{}_ahhahaha.pkl'.format(i))\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_index_new.shape)\n",
    "train_index_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(valid_index_new.shape)\n",
    "valid_index_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.values"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
